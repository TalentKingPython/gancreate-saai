{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of FYP",
      "provenance": [],
      "collapsed_sections": [
        "UGb-pRdlKcjD",
        "wI3qY3ocKiU7",
        "ipK1spN2b2XY",
        "se4UBp6bjCNV"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8d2defd6a4e4f56a96a9dab7718aac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e523c3f102f14a6fa60cd5b74c4b48ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a23ea6464e643d5ad642fd2ac9864b6",
              "IPY_MODEL_9b3f973175a44a96b28f01f3b2be5ee6",
              "IPY_MODEL_8e171faf256a481aafac35d0416f5001"
            ]
          }
        },
        "e523c3f102f14a6fa60cd5b74c4b48ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a23ea6464e643d5ad642fd2ac9864b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_967eb2d314f44aec89a0d1c6bed078f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40111ff076384a9297ead2f816aff1cb"
          }
        },
        "9b3f973175a44a96b28f01f3b2be5ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_90c4a4ed8f9e4343b5ff7dc507342829",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 89843225,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 89843225,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fe6e45e0c2b4542800ce9ff6251dc94"
          }
        },
        "8e171faf256a481aafac35d0416f5001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_767b54422b024a958e28adc0604c8326",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 85.7M/85.7M [00:04&lt;00:00, 26.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bd2eef682944619ab06d381d2dc390d"
          }
        },
        "967eb2d314f44aec89a0d1c6bed078f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40111ff076384a9297ead2f816aff1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90c4a4ed8f9e4343b5ff7dc507342829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fe6e45e0c2b4542800ce9ff6251dc94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "767b54422b024a958e28adc0604c8326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bd2eef682944619ab06d381d2dc390d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4539b483292426dadd6aa0d0f74ac38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_28ce95a28cf04278999daed8a099a2c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8be477635be44e9f87dff8af41017553",
              "IPY_MODEL_ff6feac3822e4bcea52220ee2f00d8cd",
              "IPY_MODEL_a3e566c81fe642479a5c29a01f96cedc"
            ]
          }
        },
        "28ce95a28cf04278999daed8a099a2c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8be477635be44e9f87dff8af41017553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57280342733a429fa2d327788d8c1a87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b07dded0028443e86a65b02c9afcfdf"
          }
        },
        "ff6feac3822e4bcea52220ee2f00d8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ced67228d3bd477bab466e8e1c4ae3ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 95641761,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 95641761,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_394d9c1390f1484f82d47899bbabbde9"
          }
        },
        "a3e566c81fe642479a5c29a01f96cedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1453a0cf1f94168993482ffe76fa721",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 91.2M/91.2M [00:04&lt;00:00, 26.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1047a5345a34e028d4ba5a2f38f2c31"
          }
        },
        "57280342733a429fa2d327788d8c1a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b07dded0028443e86a65b02c9afcfdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ced67228d3bd477bab466e8e1c4ae3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "394d9c1390f1484f82d47899bbabbde9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1453a0cf1f94168993482ffe76fa721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1047a5345a34e028d4ba5a2f38f2c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkBXmZVECvJk"
      },
      "source": [
        "# API Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Y2dxr6ZhC2D6",
        "outputId": "d1de2355-f8e9-497e-cfb7-fbdfe33d040e"
      },
      "source": [
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n",
        "\n",
        "!pip install ninja opensimplex gradio moviepy==1.0.3 tts pyrebase\n",
        "!apt install ffmpeg\n",
        "!pip install git+https://github.com/1adrianb/face-alignment@v1.0.1\n",
        "!pip install fbpca boto3 requests==2.23.0 #urllib3==1.25.11\n",
        "# !git submodule update --init --recursive\n",
        "!python -c \"import nltk; nltk.download('wordnet')\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 200})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting opensimplex\n",
            "  Downloading opensimplex-0.3-py3-none-any.whl (15 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-2.3.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 39.9 MB/s \n",
            "\u001b[?25hCollecting moviepy==1.0.3\n",
            "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
            "\u001b[K     |████████████████████████████████| 388 kB 50.4 MB/s \n",
            "\u001b[?25hCollecting tts\n",
            "  Downloading TTS-0.2.2.tar.gz (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 34.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyrebase\n",
            "  Downloading Pyrebase-3.0.27-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.3) (4.62.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.3) (2.23.0)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading proglog-0.1.9.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.3) (1.19.5)\n",
            "Collecting imageio<3.0,>=2.5\n",
            "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 29.0 MB/s \n",
            "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
            "  Downloading imageio_ffmpeg-0.4.5-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 130 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.5->moviepy==1.0.3) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.5)\n",
            "Collecting paramiko\n",
            "  Downloading paramiko-2.7.2-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.4)\n",
            "Collecting flask-cachebuster\n",
            "  Downloading Flask-CacheBuster-1.0.0.tar.gz (3.1 kB)\n",
            "Collecting markdown2\n",
            "  Downloading markdown2-2.4.1-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.1)\n",
            "Collecting Flask-Login\n",
            "  Downloading Flask_Login-0.5.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting Flask-Cors>=3.0.8\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 31.0 MB/s \n",
            "\u001b[?25hCollecting analytics-python\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (2.11.3)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from Flask-Cors>=3.0.8->gradio) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.1->gradio) (2.0.1)\n",
            "Collecting fsspec>=2021.04.0\n",
            "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 53.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from tts) (3.13)\n",
            "Collecting mecab-python3==1.0.3\n",
            "  Downloading mecab_python3-1.0.3-cp37-cp37m-manylinux1_x86_64.whl (487 kB)\n",
            "\u001b[K     |████████████████████████████████| 487 kB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from tts) (0.10.3.post1)\n",
            "Collecting umap-learn==0.5.1\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from tts) (0.29.24)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 44.1 MB/s \n",
            "\u001b[?25hCollecting pysbd\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting pypinyin\n",
            "  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 37.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from tts) (3.6.4)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from tts) (1.9.0+cu102)\n",
            "Collecting librosa==0.8.0\n",
            "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 48.3 MB/s \n",
            "\u001b[?25hCollecting pyworld\n",
            "  Downloading pyworld-0.3.0.tar.gz (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 41.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coqpit\n",
            "  Downloading coqpit-0.0.14-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from tts) (0.42.1)\n",
            "Collecting gruut[cs,de,es,fr,it,nl,pt,ru,sv]~=1.2.0\n",
            "  Downloading gruut-1.2.3.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 20.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from tts) (2.1.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 48.8 MB/s \n",
            "\u001b[?25hCollecting numba==0.53\n",
            "  Downloading numba-0.53.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 41.6 MB/s \n",
            "\u001b[?25hCollecting unidic-lite==1.0.8\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4 MB 60 kB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->tts) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->tts) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->tts) (1.0.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->tts) (0.2.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->tts) (1.4.0)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.53->tts) (57.4.0)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.4.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.6 MB/s \n",
            "\u001b[?25hCollecting Babel~=2.8.0\n",
            "  Downloading Babel-2.8.1-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 9.2 MB/s \n",
            "\u001b[?25hCollecting gruut-ipa~=0.9.0\n",
            "  Downloading gruut-ipa-0.9.3.tar.gz (34 kB)\n",
            "Collecting jsonlines~=1.2.0\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting num2words==0.5.10\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.4 MB/s \n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 57.6 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_ru~=1.2.0\n",
            "  Downloading gruut_lang_ru-1.2.tar.gz (16.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.9 MB 269 kB/s \n",
            "\u001b[?25hCollecting gruut_lang_nl~=1.2.0\n",
            "  Downloading gruut_lang_nl-1.2.tar.gz (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_sv~=1.2.0\n",
            "  Downloading gruut_lang_sv-1.2.tar.gz (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 31.7 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_cs~=1.2.0\n",
            "  Downloading gruut_lang_cs-1.2.tar.gz (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 23.8 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_it~=1.2.0\n",
            "  Downloading gruut_lang_it-1.2.tar.gz (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 35.8 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_de~=1.2.0\n",
            "  Downloading gruut_lang_de-1.2.tar.gz (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 22.5 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_es~=1.2.0\n",
            "  Downloading gruut_lang_es-1.2.tar.gz (15.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 195 kB/s \n",
            "\u001b[?25hCollecting gruut_lang_pt~=1.2.0\n",
            "  Downloading gruut_lang_pt-1.2.tar.gz (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 35.6 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_fr~=1.2.0\n",
            "  Downloading gruut_lang_fr-1.2.1.tar.gz (12.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.1 MB 22.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words==0.5.10->gruut[cs,de,es,fr,it,nl,pt,ru,sv]~=1.2.0->tts) (0.6.2)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from Babel~=2.8.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]~=1.2.0->tts) (2018.9)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->tts) (1.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->tts) (21.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->tts) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->tts) (2.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->tts) (3.7.4.3)\n",
            "Collecting requests<3.0,>=2.8.1\n",
            "  Downloading requests-2.11.1-py2.py3-none-any.whl (514 kB)\n",
            "\u001b[K     |████████████████████████████████| 514 kB 46.7 MB/s \n",
            "\u001b[?25hCollecting oauth2client==3.0.0\n",
            "  Downloading oauth2client-3.0.0.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting python-jwt==2.0.1\n",
            "  Downloading python_jwt-2.0.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.4.3.tar.gz (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 20.2 MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt==0.7.0\n",
            "  Downloading requests_toolbelt-0.7.0-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.0 MB/s \n",
            "\u001b[?25hCollecting gcloud==0.17.0\n",
            "  Downloading gcloud-0.17.0.tar.gz (458 kB)\n",
            "\u001b[K     |████████████████████████████████| 458 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from gcloud==0.17.0->pyrebase) (0.17.4)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.7/dist-packages (from gcloud==0.17.0->pyrebase) (1.53.0)\n",
            "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.7/dist-packages (from gcloud==0.17.0->pyrebase) (3.17.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (4.7.2)\n",
            "Collecting jws>=0.1.3\n",
            "  Downloading jws-0.1.3.tar.gz (8.1 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.3.1)\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 35.2 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
            "\u001b[K     |████████████████████████████████| 961 kB 37.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: moviepy, proglog, tts, librosa, umap-learn, unidic-lite, gruut, gruut-ipa, gruut-lang-cs, gruut-lang-de, gruut-lang-es, gruut-lang-fr, gruut-lang-it, gruut-lang-nl, gruut-lang-pt, gruut-lang-ru, gruut-lang-sv, pynndescent, gcloud, oauth2client, pycryptodome, jws, ffmpy, flask-cachebuster, pyworld\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110744 sha256=91fe6f0f8db6bdb9f2355fd8e9af2c4a5d0d635183784a2f032152214c1d438d\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/dc/2b/9cd600d483c04af3353d66623056fc03faed76b7518faae4df\n",
            "  Building wheel for proglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for proglog: filename=proglog-0.1.9-py3-none-any.whl size=6157 sha256=64d12892c82fbfb56994ec9b4d349560be17fb2cd6fdf45455979c7c70b4b409\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/36/1f/dc61e6ac10781d63cf6fa045eb09fa613a667384e12cb6e6e0\n",
            "  Building wheel for tts (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tts: filename=TTS-0.2.2-cp37-cp37m-linux_x86_64.whl size=561483 sha256=6a6a9699cfb57a941fe4dace4b7b96e89cca253cab4200750664fde1cc285eac\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/b2/df/b3419f79638f8d2f3e7bf328b6b3cf3e2ccdc0a4ed15fb9de8\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201395 sha256=236c8aee1dd9419b75764d509c77ae6cdd124cad90adc175edf9ff66d9cedc6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/1e/aa/d91797ae7e1ce11853ee100bee9d1781ae9d750e7458c95afb\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76564 sha256=846fe50e3324e6a7dc2e55ae6bc16f8219b9000916d6961d15c93e52e3a45382\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/e7/bb/347dc0e510803d7116a13d592b10cc68262da56a8eec4dd72f\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658836 sha256=db5d20c08a9d25d0ca155715ec3b27e663fe493b4da84766acb2db47e59f0a66\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/69/b1/112140b599f2b13f609d485a99e357ba68df194d2079c5b1a2\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-1.2.3-py3-none-any.whl size=11091278 sha256=a49b9574fa37cfc88967635951697dda3f271ee206a3d83403c02b4cf5c16406\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/b4/52/94a0c0762e55a284000bc16c089a4239c600749a5b9f0f31ad\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.9.3-py3-none-any.whl size=39001 sha256=2856b6ab4f3bed23b941ac05285edfd6ce66c1120c1bc9eebcc3870f7fff535f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/54/14/3e4f28f11774f67536576662cb932b3cac8428e26be86b3410\n",
            "  Building wheel for gruut-lang-cs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-cs: filename=gruut_lang_cs-1.2-py3-none-any.whl size=5796595 sha256=e0d6f99fbb47fd439e0cd09e0d44ccb63908ee232a8ed2a19fdc6734d7dafd42\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/c6/7a/44b8bab3aedb5b889ef425c2e516019c7e9e9869125d3c2dc6\n",
            "  Building wheel for gruut-lang-de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-de: filename=gruut_lang_de-1.2-py3-none-any.whl size=9574679 sha256=a3270a908fc3284ed38f7bc37d89676e6c0544a5cfa2c9846b6c522094a1dc61\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/1f/2c/a23ce1aac2c09cf617df745642d280e0be6f894862f63c05b4\n",
            "  Building wheel for gruut-lang-es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-es: filename=gruut_lang_es-1.2-py3-none-any.whl size=15403815 sha256=62d5aebd1edcd41de141db0f411fc04ccf1b7dd3c47f766c8a5f9cfdb257f3bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/57/11/d4a2445ff6dd3a228db36548f95c1f763d3defbff2b7fcdb85\n",
            "  Building wheel for gruut-lang-fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-fr: filename=gruut_lang_fr-1.2.1-py3-none-any.whl size=12103216 sha256=1fb11b295ec3b05fae70c7b4ddd0a6805269004fa4f6ac69c0836919ff7a4b77\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/62/e7/e103446f6db651133ac6871bfe0a6a582f00a74a1f0c44ca2f\n",
            "  Building wheel for gruut-lang-it (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-it: filename=gruut_lang_it-1.2-py3-none-any.whl size=1944818 sha256=b410b81d3de8bea08efa9cd8db90dbfa132da46a0e3bed3dfe170f235cb45243\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/f4/2d/0dc17ee06d958a37a6a873d7ba15bb90f710e307941dc8928f\n",
            "  Building wheel for gruut-lang-nl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-nl: filename=gruut_lang_nl-1.2-py3-none-any.whl size=7399313 sha256=7a343bba3c2ddef433f5681167dbfebff70f21bceb8dea6cd775ce78c56db810\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/c0/d8/125b811bf3df62785bffbfdccafe9d414ebc4770a35080669b\n",
            "  Building wheel for gruut-lang-pt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-pt: filename=gruut_lang_pt-1.2-py3-none-any.whl size=3412234 sha256=98d888917ab8ac60fe620d0a5b993dc583f1b467a28b6986ca175d77a0d976a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/c6/e2/458765db8d0ded8b33a1fc7551d28e5ae06b450ff5af0a585c\n",
            "  Building wheel for gruut-lang-ru (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-ru: filename=gruut_lang_ru-1.2-py3-none-any.whl size=16955789 sha256=9479c3ef15a1d9f2a57efe060dfe2ddfb90cbf1b6e2bde310a763781d69dbb7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/36/50/5375078bb647157ed425620b69fc87ba9830161886c600d175\n",
            "  Building wheel for gruut-lang-sv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-sv: filename=gruut_lang_sv-1.2-py3-none-any.whl size=2104835 sha256=8c8f493670fc2f9e07e08d017436b4d160ce56c3b03b5475b1d88fc73e8840ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/2c/0b/a087fc907ed77d1dde8df72ab70fffde05ea8bcf06b33b1acb\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.4-py3-none-any.whl size=52373 sha256=9840af3f91126b7ac57a08feaf5ac846529f829c582d0c1ade1a33b765b4b46b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/5b/62/3401692ddad12324249c774c4b15ccb046946021e2b581c043\n",
            "  Building wheel for gcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcloud: filename=gcloud-0.17.0-py3-none-any.whl size=638015 sha256=e08f38be448cedda9357941e6ec3b624d6d0b2d3a4d32853bd4f97526487ca09\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/10/90/62a8de50d755940978e1473ed4ce4b579664fcc16077d0dc99\n",
            "  Building wheel for oauth2client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oauth2client: filename=oauth2client-3.0.0-py3-none-any.whl size=106375 sha256=9d55cee78fce18ea55ec2ce5e921ad1479e54e49afeed4d7517640c69fcac7cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/73/7a/3b3f76a2142176605ff38fbca574327962c71e25a43197a4c1\n",
            "  Building wheel for pycryptodome (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycryptodome: filename=pycryptodome-3.4.3-cp37-cp37m-linux_x86_64.whl size=6814284 sha256=86ac8b26967ea8f4f43b4ea3b0bf4bb703392984ae32e4ebb6bbce626f6e67d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/83/08/de4131c0bbbbafa5bf3bd64cb0e86d40bed3ee43f3ff307112\n",
            "  Building wheel for jws (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jws: filename=jws-0.1.3-py3-none-any.whl size=9410 sha256=3d41576e9074cbdc4d87aff33b6eec1c72ed774b9a5aa4573f0f0febcd5337eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/ff/95/daf0797fca284304b39ee45749e750fdcdcaa081d46dc8fd99\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4710 sha256=c1cdfbcb8fb6bdd95333a65e028283fc4fe5f487edc33ef69e03f89c1c7339ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-cachebuster: filename=Flask_CacheBuster-1.0.0-py3-none-any.whl size=3371 sha256=5553146a3196f72c302eb45c396f09ad2f71ef6325d7707f48d82dd4d8b93ff8\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/c0/c4/44687421dab41455be93112bd1b0dee1f3c5a9aa27bee63708\n",
            "  Building wheel for pyworld (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.0-cp37-cp37m-linux_x86_64.whl size=609070 sha256=5e9a29a02abd4a930e26dcbfaad4723c7e9e5273f107fb61d00eb8213981e7b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/7c/11/c775fffa0e1e7b05a6604b4323408a77f80fb4ab304d96b5c6\n",
            "Successfully built moviepy proglog tts librosa umap-learn unidic-lite gruut gruut-ipa gruut-lang-cs gruut-lang-de gruut-lang-es gruut-lang-fr gruut-lang-it gruut-lang-nl gruut-lang-pt gruut-lang-ru gruut-lang-sv pynndescent gcloud oauth2client pycryptodome jws ffmpy flask-cachebuster pyworld\n",
            "Installing collected packages: llvmlite, requests, python-crfsuite, numba, num2words, jsonlines, gruut-ipa, Babel, pynndescent, pynacl, oauth2client, monotonic, jws, gruut-lang-sv, gruut-lang-ru, gruut-lang-pt, gruut-lang-nl, gruut-lang-it, gruut-lang-fr, gruut-lang-es, gruut-lang-de, gruut-lang-cs, gruut, cryptography, bcrypt, backoff, unidic-lite, umap-learn, tensorboardX, requests-toolbelt, pyworld, python-jwt, pysbd, pypinyin, pycryptodome, proglog, paramiko, mecab-python3, markdown2, librosa, imageio-ffmpeg, imageio, gcloud, fsspec, Flask-Login, Flask-Cors, flask-cachebuster, ffmpy, coqpit, anyascii, analytics-python, tts, pyrebase, opensimplex, ninja, moviepy, gradio\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: Babel\n",
            "    Found existing installation: Babel 2.9.1\n",
            "    Uninstalling Babel-2.9.1:\n",
            "      Successfully uninstalled Babel-2.9.1\n",
            "  Attempting uninstall: oauth2client\n",
            "    Found existing installation: oauth2client 4.1.3\n",
            "    Uninstalling oauth2client-4.1.3:\n",
            "      Successfully uninstalled oauth2client-4.1.3\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.0.1 requires requests>=2.19.0, but you have requests 2.11.1 which is incompatible.\n",
            "tensorboard 2.6.0 requires requests<3,>=2.21.0, but you have requests 2.11.1 which is incompatible.\n",
            "spacy 2.2.4 requires requests<3.0.0,>=2.13.0, but you have requests 2.11.1 which is incompatible.\n",
            "pydrive 1.3.1 requires oauth2client>=4.0.0, but you have oauth2client 3.0.0 which is incompatible.\n",
            "pandas-datareader 0.9.0 requires requests>=2.19.0, but you have requests 2.11.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.11.1 which is incompatible.\n",
            "google-api-core 1.26.3 requires requests<3.0.0dev,>=2.18.0, but you have requests 2.11.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Babel-2.8.1 Flask-Cors-3.0.10 Flask-Login-0.5.0 analytics-python-1.4.0 anyascii-0.3.0 backoff-1.10.0 bcrypt-3.2.0 coqpit-0.0.14 cryptography-3.4.8 ffmpy-0.3.0 flask-cachebuster-1.0.0 fsspec-2021.8.1 gcloud-0.17.0 gradio-2.3.0 gruut-1.2.3 gruut-ipa-0.9.3 gruut-lang-cs-1.2 gruut-lang-de-1.2 gruut-lang-es-1.2 gruut-lang-fr-1.2.1 gruut-lang-it-1.2 gruut-lang-nl-1.2 gruut-lang-pt-1.2 gruut-lang-ru-1.2 gruut-lang-sv-1.2 imageio-2.9.0 imageio-ffmpeg-0.4.5 jsonlines-1.2.0 jws-0.1.3 librosa-0.8.0 llvmlite-0.36.0 markdown2-2.4.1 mecab-python3-1.0.3 monotonic-1.6 moviepy-1.0.3 ninja-1.10.2 num2words-0.5.10 numba-0.53.0 oauth2client-3.0.0 opensimplex-0.3 paramiko-2.7.2 proglog-0.1.9 pycryptodome-3.4.3 pynacl-1.4.0 pynndescent-0.5.4 pypinyin-0.42.0 pyrebase-3.0.27 pysbd-0.3.4 python-crfsuite-0.9.7 python-jwt-2.0.1 pyworld-0.3.0 requests-2.11.1 requests-toolbelt-0.7.0 tensorboardX-2.4 tts-0.2.2 umap-learn-0.5.1 unidic-lite-1.0.8\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Collecting git+https://github.com/1adrianb/face-alignment@v1.0.1\n",
            "  Cloning https://github.com/1adrianb/face-alignment (to revision v1.0.1) to /tmp/pip-req-build-nqw83_nh\n",
            "  Running command git clone -q https://github.com/1adrianb/face-alignment /tmp/pip-req-build-nqw83_nh\n",
            "  Running command git checkout -q 87a496b158ff9a215aa6f48262f4e13d8e6c4dd7\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from face-alignment==1.0.1) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face-alignment==1.0.1) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from face-alignment==1.0.1) (1.4.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from face-alignment==1.0.1) (0.16.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from face-alignment==1.0.1) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from face-alignment==1.0.1) (4.62.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment==1.0.1) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment==1.0.1) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment==1.0.1) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment==1.0.1) (2.6.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment==1.0.1) (2.9.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment==1.0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment==1.0.1) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment==1.0.1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment==1.0.1) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment==1.0.1) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->face-alignment==1.0.1) (3.7.4.3)\n",
            "Building wheels for collected packages: face-alignment\n",
            "  Building wheel for face-alignment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-alignment: filename=face_alignment-1.0.1-py2.py3-none-any.whl size=22899 sha256=0318eb394c68b609f179a7b62bbb8a0c0f6a5e68ec7b44f7f3b811787285715b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2jqg62nj/wheels/37/83/21/9ae379e23a548af5d4eb335071fda470d2857c7811ba7079a9\n",
            "Successfully built face-alignment\n",
            "Installing collected packages: face-alignment\n",
            "Successfully installed face-alignment-1.0.1\n",
            "Collecting fbpca\n",
            "  Downloading fbpca-1.0.tar.gz (11 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.18.40-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting requests==2.23.0\n",
            "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (1.24.3)\n",
            "Collecting botocore<1.22.0,>=1.21.40\n",
            "  Downloading botocore-1.21.40-py3-none-any.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 28.2 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.40->boto3) (2.8.2)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.40->boto3) (1.15.0)\n",
            "Building wheels for collected packages: fbpca\n",
            "  Building wheel for fbpca (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fbpca: filename=fbpca-1.0-py3-none-any.whl size=11376 sha256=cff3502102843541a680d39d5d5d6c6774763a452908da981f35e39f1bc6c50e\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/08/0c/1b9866c35c8d3f136d100dfe88036a32e0795437daca089f70\n",
            "Successfully built fbpca\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, requests, fbpca, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.11.1\n",
            "    Uninstalling requests-2.11.1:\n",
            "      Successfully uninstalled requests-2.11.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyrebase 3.0.27 requires requests==2.11.1, but you have requests 2.23.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.40 botocore-1.21.40 fbpca-1.0 jmespath-0.10.0 requests-2.23.0 s3transfer-0.5.0 urllib3-1.25.11\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jib1bUT4C6Cr",
        "outputId": "5d3932a3-cf67-4d97-a631-2085cd59639f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ10zR_J6-cB",
        "outputId": "8607bdcd-a35f-475f-c6ad-fdc57f6963a7"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab/fyp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab/fyp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS3FVFRIC_wM",
        "outputId": "ecf018bc-a033-4c26-f59d-5a6b17119671"
      },
      "source": [
        "try: # set up path\n",
        "    import sys\n",
        "    sys.path.append('/content/drive/MyDrive/Colab/fyp/ganspace')\n",
        "    sys.path.append('/content/drive/MyDrive/Colab/fyp/first-order-model')\n",
        "    sys.path.append('/content/drive/MyDrive/Colab/fyp/iPERCore')\n",
        "    sys.path.append('/content/drive/MyDrive/Colab/fyp/Wav2Lip')\n",
        "    print('Paths added')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paths added\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "04KOp1ofD3SG",
        "outputId": "7acf1f21-7561-4951-b55d-868c5c6d4a6b"
      },
      "source": [
        "#@title Install impersonator dependencies\n",
        "# set CUDA_HOME, here we use CUDA 10.1\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n",
        "\n",
        "import os\n",
        "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda-10.1\"\n",
        "\n",
        "!echo $CUDA_HOME\n",
        "%cd /content/drive/MyDrive/Colab/fyp/iPERCore/\n",
        "!python setup.py develop\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 200})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda-10.1\n",
            "/content/drive/MyDrive/Colab/fyp/iPERCore\n",
            "Cuda version is 10.1\n",
            "/usr/bin/python3 -m pip install pip==20.2.4\n",
            "Collecting pip==20.2.4\n",
            "  Downloading pip-20.2.4-py2.py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pip-tools 6.2.0 requires pip>=20.3, but you have pip 20.2.4 which is incompatible.\u001b[0m\n",
            "Successfully installed pip-20.2.4\n",
            "/usr/bin/python3 -m pip install torch==1.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (735.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.3 MB 23 kB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (3.7.4.3)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you'll have torch 1.7.0+cu101 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you'll have torch 1.7.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0+cu101\n",
            "/usr/bin/python3 -m pip install torchvision==0.8.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torchvision==0.8.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1+cu101) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1+cu101) (1.7.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1+cu101) (0.6)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Successfully installed torchvision-0.8.1+cu101\n",
            "/usr/bin/python3 -m pip install mmcv-full==1.2.0 -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/index.html\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/index.html\n",
            "Collecting mmcv-full==1.2.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/mmcv_full-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (19.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.8 MB 271 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.2.0) (3.13)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.2.0) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.2.0) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.2.0) (7.1.2)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.2.0 yapf-0.31.0\n",
            "/usr/bin/python3 -m pip install numpy>=1.19.3\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "/usr/bin/python3 -m pip install numpy>=1.19.3\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "/usr/bin/python3 -m pip install scipy>=1.5.2\n",
            "Collecting scipy>=1.5.2\n",
            "  Downloading scipy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.5 MB 76 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.5.2) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.7.1\n",
            "/usr/bin/python3 -m pip install scikit-image>=0.17.2\n",
            "Collecting scikit-image>=0.17.2\n",
            "  Downloading scikit_image-0.18.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (29.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 121 kB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (1.19.5)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (1.7.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (2021.8.30)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (2.6.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (1.15.0)\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-image-0.18.3\n",
            "/usr/bin/python3 -m pip install opencv-python>=4.4.0.40\n",
            "Collecting opencv-python>=4.4.0.40\n",
            "  Downloading opencv_python-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.9 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.4.0.40) (1.19.5)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-4.5.3.56\n",
            "/usr/bin/python3 -m pip install tensorboardX>=2.1\n",
            "Requirement already satisfied: tensorboardX>=2.1 in /usr/local/lib/python3.7/dist-packages (2.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=2.1) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=2.1) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX>=2.1) (1.15.0)\n",
            "/usr/bin/python3 -m pip install tqdm>=4.48.2\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "/usr/bin/python3 -m pip install visdom>=0.1.8.9\n",
            "Collecting visdom>=0.1.8.9\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (1.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (22.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.9) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.9) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.9) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.9) (1.25.11)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.1-py2.py3-none-any.whl (7.4 kB)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=9c230dbacf5d4e2db434e6337b169149153c53de067b681a2d084ae0e035337b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5710 sha256=bc4b8455fc276796471d8b196c64401708e6aef00683506e04a81ba7cb7cf42a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed jsonpatch-1.32 jsonpointer-2.1 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-1.2.1\n",
            "/usr/bin/python3 -m pip install easydict>=1.9\n",
            "Requirement already satisfied: easydict>=1.9 in /usr/local/lib/python3.7/dist-packages (1.9)\n",
            "/usr/bin/python3 -m pip install toml>=0.10.2\n",
            "Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "/usr/bin/python3 -m pip install git+https://github.com/open-mmlab/mmdetection.git@8179440ec5f75fe95484854af61ce6f6279f3bbc\n",
            "Collecting git+https://github.com/open-mmlab/mmdetection.git@8179440ec5f75fe95484854af61ce6f6279f3bbc\n",
            "  Cloning https://github.com/open-mmlab/mmdetection.git (to revision 8179440ec5f75fe95484854af61ce6f6279f3bbc) to /tmp/pip-req-build-lbg0vgdd\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.6.0) (3.2.2)\n",
            "Collecting mmpycocotools\n",
            "  Downloading mmpycocotools-12.0.3.tar.gz (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.6.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.6.0) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.6.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.6.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.6.0) (2.4.7)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from mmpycocotools->mmdet==2.6.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from mmpycocotools->mmdet==2.6.0) (0.29.24)\n",
            "Building wheels for collected packages: mmdet, mmpycocotools, terminaltables\n",
            "  Building wheel for mmdet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmdet: filename=mmdet-2.6.0-py3-none-any.whl size=490174 sha256=fa12d27568780367a052ebfa9761b307129b56b214bacbafa3624c736870e761\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/07/c9/55f832a7f1740f48e9ef244ed2b15d6bb042b75244ce041edd\n",
            "  Building wheel for mmpycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmpycocotools: filename=mmpycocotools-12.0.3-cp37-cp37m-linux_x86_64.whl size=264251 sha256=609eb25a3a17d498cb1f40d07a48ff379b1af234e4329213d70ad35b7101baab\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/fa/4a/067979eccddf6a22b46722493df8e07b0541956a5ab5bac8b1\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=dcf66a542518bfd7263ae378b33e2b7a94eedabd8cc0bda1bc6109ec0aba7ffd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
            "Successfully built mmdet mmpycocotools terminaltables\n",
            "Installing collected packages: mmpycocotools, terminaltables, mmdet\n",
            "Successfully installed mmdet-2.6.0 mmpycocotools-12.0.3 terminaltables-3.1.0\n",
            "/usr/bin/python3 -m pip install git+https://github.com/open-mmlab/mmediting@d4086aaf8a36ae830f1714aad585900d24ad1156\n",
            "Collecting git+https://github.com/open-mmlab/mmediting@d4086aaf8a36ae830f1714aad585900d24ad1156\n",
            "  Cloning https://github.com/open-mmlab/mmediting (to revision d4086aaf8a36ae830f1714aad585900d24ad1156) to /tmp/pip-req-build-tq_6gldd\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (0.99)\n",
            "Requirement already satisfied: mmcv-full>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (1.2.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (0.18.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (2.6.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (0.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (3.13)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (7.1.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (2.4.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (4.5.3.56)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (2021.8.30)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (2.9.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (2.6.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (1.7.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (1.34.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (1.39.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (3.17.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard->mmedit==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->mmedit==0.5.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->mmedit==0.5.0) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->mmedit==0.5.0) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->mmedit==0.5.0) (4.6.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (2021.5.30)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->mmedit==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->mmedit==0.5.0) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->mmedit==0.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->mmedit==0.5.0) (3.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->mmedit==0.5.0) (3.1.1)\n",
            "Building wheels for collected packages: mmedit\n",
            "  Building wheel for mmedit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmedit: filename=mmedit-0.5.0-py2.py3-none-any.whl size=220163 sha256=678bbecfeca959731f9dcfbf54863123831f43b7f6260206fd3b5651f9dccb50\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/96/40/2b20e71f449b7769d9626c6197c4e10693fa5853b7345f9bdd\n",
            "Successfully built mmedit\n",
            "Installing collected packages: mmedit\n",
            "Successfully installed mmedit-0.5.0\n",
            "/usr/bin/python3 -m pip install git+https://github.com/iPERDance/neural_renderer.git@e5f54f71a8941acf372514eb92e289872f272653\n",
            "Collecting git+https://github.com/iPERDance/neural_renderer.git@e5f54f71a8941acf372514eb92e289872f272653\n",
            "  Cloning https://github.com/iPERDance/neural_renderer.git (to revision e5f54f71a8941acf372514eb92e289872f272653) to /tmp/pip-req-build-_694c8fv\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (0.8.1+cu101)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (4.62.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->neural-renderer==1.1.3) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->neural-renderer==1.1.3) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch->neural-renderer==1.1.3) (0.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->neural-renderer==1.1.3) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (1.1.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (2021.8.30)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (2.6.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (1.7.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (1.15.0)\n",
            "Building wheels for collected packages: neural-renderer\n",
            "  Building wheel for neural-renderer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neural-renderer: filename=neural_renderer-1.1.3-cp37-cp37m-linux_x86_64.whl size=5675340 sha256=633994f8eafb27c1f9ca8eb74f1847e03156e39b10be093f640755caae2a826c\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/62/a4/71ebf253f9481f653ec789c5e0ac11c14a31fac223001a7a3f\n",
            "Successfully built neural-renderer\n",
            "Installing collected packages: neural-renderer\n",
            "Successfully installed neural-renderer-1.1.3\n",
            "running develop\n",
            "running egg_info\n",
            "writing iPERCore.egg-info/PKG-INFO\n",
            "writing dependency_links to iPERCore.egg-info/dependency_links.txt\n",
            "writing entry points to iPERCore.egg-info/entry_points.txt\n",
            "writing requirements to iPERCore.egg-info/requires.txt\n",
            "writing top-level names to iPERCore.egg-info/top_level.txt\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'iPERCore.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/dist-packages/iPERCore.egg-link (link to .)\n",
            "Adding iPERCore 0.2.0 to easy-install.pth file\n",
            "Installing run_imitator script to /usr/local/bin\n",
            "Installing run_swapper script to /usr/local/bin\n",
            "Installing run_viewer script to /usr/local/bin\n",
            "\n",
            "Installed /content/drive/My Drive/Colab/fyp/iPERCore\n",
            "Processing dependencies for iPERCore==0.2.0\n",
            "Searching for toml==0.10.2\n",
            "Best match: toml 0.10.2\n",
            "Adding toml 0.10.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for easydict==1.9\n",
            "Best match: easydict 1.9\n",
            "Adding easydict 1.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for visdom==0.1.8.9\n",
            "Best match: visdom 0.1.8.9\n",
            "Adding visdom 0.1.8.9 to easy-install.pth file\n",
            "Installing visdom script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.62.0\n",
            "Best match: tqdm 4.62.0\n",
            "Adding tqdm 4.62.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboardX==2.4\n",
            "Best match: tensorboardX 2.4\n",
            "Adding tensorboardX 2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for opencv-python==4.5.3.56\n",
            "Best match: opencv-python 4.5.3.56\n",
            "Adding opencv-python 4.5.3.56 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scikit-image==0.18.3\n",
            "Best match: scikit-image 0.18.3\n",
            "Adding scikit-image 0.18.3 to easy-install.pth file\n",
            "Installing skivi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.7.1\n",
            "Best match: scipy 1.7.1\n",
            "Adding scipy 1.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyzmq==22.2.1\n",
            "Best match: pyzmq 22.2.1\n",
            "Adding pyzmq 22.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for jsonpatch==1.32\n",
            "Best match: jsonpatch 1.32\n",
            "Adding jsonpatch 1.32 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torchfile==0.1.0\n",
            "Best match: torchfile 0.1.0\n",
            "Adding torchfile 0.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for websocket-client==1.2.1\n",
            "Best match: websocket-client 1.2.1\n",
            "Adding websocket-client 1.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tornado==5.1.1\n",
            "Best match: tornado 5.1.1\n",
            "Adding tornado 5.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tifffile==2021.8.30\n",
            "Best match: tifffile 2021.8.30\n",
            "Adding tifffile 2021.8.30 to easy-install.pth file\n",
            "Installing lsm2bin script to /usr/local/bin\n",
            "Installing tiff2fsspec script to /usr/local/bin\n",
            "Installing tiffcomment script to /usr/local/bin\n",
            "Installing tifffile script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for networkx==2.6.2\n",
            "Best match: networkx 2.6.2\n",
            "Adding networkx 2.6.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyWavelets==1.1.1\n",
            "Best match: PyWavelets 1.1.1\n",
            "Adding PyWavelets 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for imageio==2.9.0\n",
            "Best match: imageio 2.9.0\n",
            "Adding imageio 2.9.0 to easy-install.pth file\n",
            "Installing imageio_download_bin script to /usr/local/bin\n",
            "Installing imageio_remove_bin script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for jsonpointer==2.1\n",
            "Best match: jsonpointer 2.1\n",
            "Adding jsonpointer 2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2021.5.30\n",
            "Best match: certifi 2021.5.30\n",
            "Adding certifi 2021.5.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.25.11\n",
            "Best match: urllib3 1.25.11\n",
            "Adding urllib3 1.25.11 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.3.1\n",
            "Best match: kiwisolver 1.3.1\n",
            "Adding kiwisolver 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==2.4.7\n",
            "Best match: pyparsing 2.4.7\n",
            "Adding pyparsing 2.4.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for iPERCore==0.2.0\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnsBkNM4DC3K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "b8d2defd6a4e4f56a96a9dab7718aac7",
            "e523c3f102f14a6fa60cd5b74c4b48ce",
            "3a23ea6464e643d5ad642fd2ac9864b6",
            "9b3f973175a44a96b28f01f3b2be5ee6",
            "8e171faf256a481aafac35d0416f5001",
            "967eb2d314f44aec89a0d1c6bed078f6",
            "40111ff076384a9297ead2f816aff1cb",
            "90c4a4ed8f9e4343b5ff7dc507342829",
            "9fe6e45e0c2b4542800ce9ff6251dc94",
            "767b54422b024a958e28adc0604c8326",
            "8bd2eef682944619ab06d381d2dc390d",
            "a4539b483292426dadd6aa0d0f74ac38",
            "28ce95a28cf04278999daed8a099a2c5",
            "8be477635be44e9f87dff8af41017553",
            "ff6feac3822e4bcea52220ee2f00d8cd",
            "a3e566c81fe642479a5c29a01f96cedc",
            "57280342733a429fa2d327788d8c1a87",
            "8b07dded0028443e86a65b02c9afcfdf",
            "ced67228d3bd477bab466e8e1c4ae3ef",
            "394d9c1390f1484f82d47899bbabbde9",
            "a1453a0cf1f94168993482ffe76fa721",
            "e1047a5345a34e028d4ba5a2f38f2c31"
          ]
        },
        "cellView": "form",
        "outputId": "91b82e67-a4b1-4580-9697-68636a59a0ee"
      },
      "source": [
        "#@title Define Cropping Functions\n",
        "\n",
        "import os\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "import face_alignment\n",
        "import imageio\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML, clear_output\n",
        "import cv2\n",
        "import shutil\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        " \n",
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "\n",
        "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=True,\n",
        "                                      device='cuda')\n",
        "\n",
        "image_size = 512\n",
        "\n",
        "def create_bounding_box(target_landmarks, expansion_factor=1):\n",
        "    target_landmarks = np.array(target_landmarks)\n",
        "    x_y_min = target_landmarks.reshape(-1, 68, 2).min(axis=1)\n",
        "    x_y_max = target_landmarks.reshape(-1, 68, 2).max(axis=1)\n",
        "    expansion_factor = (expansion_factor-1)/2\n",
        "    bb_expansion_x = (x_y_max[:, 0] - x_y_min[:, 0]) * expansion_factor\n",
        "    bb_expansion_y = (x_y_max[:, 1] - x_y_min[:, 1]) * expansion_factor\n",
        "    x_y_min[:, 0] -= bb_expansion_x\n",
        "    x_y_max[:, 0] += bb_expansion_x\n",
        "    x_y_min[:, 1] -= bb_expansion_y\n",
        "    x_y_max[:, 1] += bb_expansion_y\n",
        "    return np.hstack((x_y_min, x_y_max-x_y_min))\n",
        "\n",
        "def fix_dims(im):\n",
        "    if im.ndim == 2:\n",
        "        im = np.tile(im[..., None], [1, 1, 3])\n",
        "    return im[...,:3]\n",
        "\n",
        "def get_crop(im, center_face=True, crop_face=True, expansion_factor=1, landmarks=None):\n",
        "    im = fix_dims(im)\n",
        "    if (center_face or crop_face) and not landmarks:\n",
        "        landmarks = fa.get_landmarks_from_image(im)\n",
        "    if (center_face or crop_face) and landmarks:\n",
        "        rects = create_bounding_box(landmarks, expansion_factor=expansion_factor)\n",
        "        x0,y0,w,h = sorted(rects, key=lambda x: x[2]*x[3])[-1]\n",
        "        if crop_face:\n",
        "            s = max(h, w)\n",
        "            x0 += (w-s)//2\n",
        "            x1 = x0 + s\n",
        "            y0 += (h-s)//2\n",
        "            y1 = y0 + s\n",
        "        else:\n",
        "            img_h,img_w = im.shape[:2]\n",
        "            img_s = min(img_h,img_w)\n",
        "            x0 = min(max(0, x0+(w-img_s)//2), img_w-img_s)\n",
        "            x1 = x0 + img_s\n",
        "            y0 = min(max(0, y0+(h-img_s)//2), img_h-img_s)\n",
        "            y1 = y0 + img_s            \n",
        "    else:\n",
        "        h,w = im.shape[:2]\n",
        "        s = min(h,w)\n",
        "        x0 = (w-s)//2\n",
        "        x1 = x0 + s\n",
        "        y0 = (h-s)//2\n",
        "        y1 = y0 + s\n",
        "    return int(x0),int(x1),int(y0),int(y1)\n",
        "\n",
        "def pad_crop_resize(im, x0=None, x1=None, y0=None, y1=None, new_h=256, new_w=256):\n",
        "    im = fix_dims(im)\n",
        "    h,w = im.shape[:2]\n",
        "    if x0 is None:\n",
        "      x0 = 0\n",
        "    if x1 is None:\n",
        "      x1 = w\n",
        "    if y0 is None:\n",
        "      y0 = 0\n",
        "    if y1 is None:\n",
        "      y1 = h\n",
        "    if x0<0 or x1>w or y0<0 or y1>h:\n",
        "        im = np.pad(im, pad_width=[(max(-y0,0),max(y1-h,0)),(max(-x0,0),max(x1-w,0)),(0,0)], mode='edge')\n",
        "    return resize(im[max(y0,0):y1-min(y0,0),max(x0,0):x1-min(x0,0)], (new_h, new_w))\n",
        "\n",
        "def get_crop_body(im, center_body=True, crop_body=True, expansion_factor=1, rects=None):\n",
        "    im = fix_dims(im)\n",
        "    if (center_body or crop_body) and rects is None:\n",
        "        rects, _ = hog.detectMultiScale(im, winStride=(4, 4),padding=(8,8), scale=expansion_factor)\n",
        "    if (center_body or crop_body) and rects is not None and len(rects):\n",
        "        x0,y0,w,h = sorted(rects, key=lambda x: x[2]*x[3])[-1]\n",
        "        if crop_body:\n",
        "            x0 += w//2-h//2\n",
        "            x1 = x0+h\n",
        "            y1 = y0+h\n",
        "        else:\n",
        "            img_h,img_w = im.shape[:2]\n",
        "            x0 += (w-img_h)//2\n",
        "            x1 = x0+img_h\n",
        "            y0 = 0\n",
        "            y1 = img_h\n",
        "    else:\n",
        "        h,w = im.shape[:2]\n",
        "        x0 = (w-h)//2\n",
        "        x1 = (w+h)//2\n",
        "        y0 = 0\n",
        "        y1 = h\n",
        "    return int(x0),int(x1),int(y0),int(y1)\n",
        "\n",
        "def crop_resize(im, size, crop=False):\n",
        "  if im.shape[:2] == size:\n",
        "    return im\n",
        "  if size[0]<im.shape[0] or size[1]<im.shape[1]:\n",
        "    interp = cv2.INTER_AREA\n",
        "  else:\n",
        "    interp = cv2.INTER_CUBIC\n",
        "  if not crop:\n",
        "    return np.clip(cv2.resize(im, size[::-1], interpolation=interp),0,1)\n",
        "  ratio = max(size[0]/im.shape[0], size[1]/im.shape[1])\n",
        "  im = np.clip(cv2.resize(im, (int(np.ceil(im.shape[1]*ratio)), int(np.ceil(im.shape[0]*ratio))), interpolation=interp),0,1)\n",
        "  return im[(im.shape[0]-size[0])//2:(im.shape[0]-size[0])//2+size[0], (im.shape[1]-size[1])//2:(im.shape[1]-size[1])//2+size[1]]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8d2defd6a4e4f56a96a9dab7718aac7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/85.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/2DFAN4-11f355bf06.pth.tar\" to /root/.cache/torch/hub/checkpoints/2DFAN4-11f355bf06.pth.tar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4539b483292426dadd6aa0d0f74ac38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/91.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "f3zKZ1bDDYSe"
      },
      "source": [
        "#@title Define GANSpace functions\n",
        "from ipywidgets import fixed\n",
        "\n",
        "# Taken from https://github.com/alexanderkuk/log-progress\n",
        "def log_progress(sequence, every=1, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "\n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "\n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n",
        "\n",
        "def name_direction(sender):\n",
        "  if not text.value:\n",
        "    print('Please name the direction before saving')\n",
        "    return\n",
        "    \n",
        "  if num in named_directions.values():\n",
        "    target_key = list(named_directions.keys())[list(named_directions.values()).index(num)]\n",
        "    print(f'Direction already named: {target_key}')\n",
        "    print(f'Overwriting... ')\n",
        "    del(named_directions[target_key])\n",
        "  named_directions[text.value] = [num, start_layer.value, end_layer.value]\n",
        "  save_direction(random_dir, text.value)\n",
        "  for item in named_directions:\n",
        "    print(item, named_directions[item])\n",
        "\n",
        "def save_direction(direction, filename):\n",
        "  filename += \".npy\"\n",
        "  np.save(filename, direction, allow_pickle=True, fix_imports=True)\n",
        "  print(f'Latent direction saved as {filename}')\n",
        "\n",
        "def project_image(target_image, step, model, center=False, seed=303, use_clip=True, video=False):\n",
        "    if model == 'portrait':\n",
        "        pkl = '/content/drive/MyDrive/Colab/models/portrait-001000.pkl'\n",
        "    elif model == 'character':\n",
        "        pkl = '/content/drive/MyDrive/Colab/models/character-002600.pkl'\n",
        "    elif model == 'model':\n",
        "        pkl = '/content/drive/MyDrive/Colab/models/modelv4-001600.pkl'\n",
        "    elif model == 'lookbook':\n",
        "        pkl = '/content/drive/MyDrive/Colab/models/lookbook-001800.pkl'\n",
        "    else:\n",
        "        print('Model PKL file does not exists')\n",
        "\n",
        "    !python /content/drive/MyDrive/Colab/fyp/stylegan2-ada-pytorch/pbaylies_projector.py --network={pkl} --outdir=/content/projector_output/ --target-image={target_image} --num-steps={step} --use-clip={use_clip} --use-center={center} --seed={seed} --save-video={video}\n",
        "\n",
        "    projected_w = np.load('/content/projector_output/projected_w.npz')['w'].squeeze()\n",
        "    return projected_w\n",
        "\n",
        "def mix_w(w1, w2, content, style):\n",
        "    for i in range(0,5):\n",
        "        w2[i] = w1[i] * (1 - content) + w2[i] * content\n",
        "\n",
        "    for i in range(5, 16):\n",
        "        w2[i] = w1[i] * (1 - style) + w2[i] * style\n",
        "    \n",
        "    return w2\n",
        "\n",
        "def display_sample_pytorch(seed=None, truncation=0.5, directions=None, distances=None, scale=1, start=0, end=14, w=None, disp=True, save=None):\n",
        "    # blockPrint()\n",
        "    model.truncation = truncation\n",
        "    if w is None:\n",
        "        w = model.sample_latent(1, seed=seed).detach().cpu().numpy()\n",
        "        w = [w]*model.get_max_latents() # one per layer\n",
        "    else:\n",
        "        w = [np.expand_dims(x, 0) for x in w]\n",
        "    \n",
        "    if directions != None and distances != None:\n",
        "        for l in range(start, end):\n",
        "          for i in range(len(directions)):\n",
        "            w[l] = w[l] + directions[i] * distances[i] * scale\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    final_im = Image.fromarray((out * 255).astype(np.uint8)).resize((500,500),Image.LANCZOS)\n",
        "    \n",
        "    \n",
        "    if save is not None:\n",
        "      if disp == False:\n",
        "        print(save)\n",
        "      final_im.save(f'out/{seed}_{save:05}.png')\n",
        "    if disp:\n",
        "      display(final_im)\n",
        "    \n",
        "    return final_im\n",
        "\n",
        "def generate_mov(seed, truncation, direction_vec, scale, layers, n_frames, out_name = 'out', noise_spec = None, loop=True):\n",
        "  \"\"\"Generates a mov moving back and forth along the chosen direction vector\"\"\"\n",
        "  # Example of reading a generated set of images, and storing as MP4.\n",
        "  %mkdir out\n",
        "  movieName = f'out/{out_name}.mp4'\n",
        "  offset = -10\n",
        "  step = 20 / n_frames\n",
        "  imgs = []\n",
        "  for i in log_progress(range(n_frames), name = \"Generating frames\"):\n",
        "    print(f'\\r{i} / {n_frames}', end='')\n",
        "    w = model.sample_latent(1, seed=seed).cpu().numpy()\n",
        "\n",
        "    model.truncation = truncation\n",
        "    w = [w]*model.get_max_latents() # one per layer\n",
        "    for l in layers:\n",
        "      if l <= model.get_max_latents():\n",
        "          w[l] = w[l] + direction_vec * offset * scale\n",
        "\n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    final_im = Image.fromarray((out * 255).astype(np.uint8))\n",
        "    imgs.append(out)\n",
        "    #increase offset\n",
        "    offset += step\n",
        "  if loop:\n",
        "    imgs += imgs[::-1]\n",
        "  with imageio.get_writer(movieName, mode='I') as writer:\n",
        "    for image in log_progress(list(imgs), name = \"Creating animation\"):\n",
        "        writer.append_data(img_as_ubyte(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-S4Syb5DSUi",
        "cellView": "form",
        "outputId": "451abe62-67c1-4d4e-a1e3-9af64614b74c"
      },
      "source": [
        "#@title Load Model for GANSpace\n",
        "selected_model = 'portrait'#@param [\"portrait\", \"character\", \"model\", \"lookbook\"]\n",
        "\n",
        "# Load model\n",
        "from IPython.utils import io\n",
        "import torch\n",
        "import PIL\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from models import get_instrumented_model\n",
        "from decomposition import get_or_compute\n",
        "from config import Config\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "# Speed up computation\n",
        "torch.autograd.set_grad_enabled(False)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Specify model to use\n",
        "config = Config(\n",
        "  model='StyleGAN2',\n",
        "  layer='style',\n",
        "  output_class=selected_model,\n",
        "  components=80,\n",
        "  use_w=True,\n",
        "  batch_size=5_000, # style layer quite small\n",
        ")\n",
        "\n",
        "inst = get_instrumented_model(config.model, config.output_class,\n",
        "                              config.layer, torch.device('cuda'), use_w=config.use_w)\n",
        "\n",
        "path_to_components = get_or_compute(config, inst)\n",
        "\n",
        "model = inst.model\n",
        "\n",
        "comps = np.load(path_to_components)\n",
        "lst = comps.files\n",
        "latent_dirs = []\n",
        "latent_stdevs = []\n",
        "\n",
        "load_activations = False\n",
        "\n",
        "for item in lst:\n",
        "    if load_activations:\n",
        "      if item == 'act_comp':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_dirs.append(comps[item][i])\n",
        "      if item == 'act_stdev':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_stdevs.append(comps[item][i])\n",
        "    else:\n",
        "      if item == 'lat_comp':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_dirs.append(comps[item][i])\n",
        "      if item == 'lat_stdev':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_stdevs.append(comps[item][i])\n",
        "\n",
        "def load_model(output_class):\n",
        "    global config\n",
        "    global inst\n",
        "    global model\n",
        "    config = Config(\n",
        "    model='StyleGAN2',\n",
        "    layer='style',\n",
        "    output_class=output_class,\n",
        "    components=80,\n",
        "    use_w=True,\n",
        "    batch_size=5_000, # style layer quite small\n",
        "  )\n",
        "\n",
        "    inst = get_instrumented_model(config.model, config.output_class,\n",
        "                                  config.layer, torch.device('cuda'), use_w=config.use_w)\n",
        "\n",
        "    path_to_components = get_or_compute(config, inst)\n",
        "\n",
        "    model = inst.model\n",
        "\n",
        "    comps = np.load(path_to_components)\n",
        "    lst = comps.files\n",
        "    latent_dirs = []\n",
        "    latent_stdevs = []\n",
        "\n",
        "    load_activations = False\n",
        "\n",
        "    for item in lst:\n",
        "        if load_activations:\n",
        "          if item == 'act_comp':\n",
        "            for i in range(comps[item].shape[0]):\n",
        "              latent_dirs.append(comps[item][i])\n",
        "          if item == 'act_stdev':\n",
        "            for i in range(comps[item].shape[0]):\n",
        "              latent_stdevs.append(comps[item][i])\n",
        "        else:\n",
        "          if item == 'lat_comp':\n",
        "            for i in range(comps[item].shape[0]):\n",
        "              latent_dirs.append(comps[item][i])\n",
        "          if item == 'lat_stdev':\n",
        "            for i in range(comps[item].shape[0]):\n",
        "              latent_stdevs.append(comps[item][i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StyleGAN2: Optimized CUDA op FusedLeakyReLU not available, using native PyTorch fallback.\n",
            "StyleGAN2: Optimized CUDA op UpFirDn2d not available, using native PyTorch fallback.\n",
            "/content/drive/MyDrive/Colab/fyp/ganspace/models/checkpoints/stylegan2/stylegan2_portrait_512.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP6w_g9iez9m"
      },
      "source": [
        "### GANSpace UI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "oUti6B_uDite",
        "cellView": "form",
        "outputId": "8167ad77-0f4d-48a0-ef8a-df8e203961f5"
      },
      "source": [
        "#@title Portrait GANSpace UI\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "def generate_image(seed, truncation,\n",
        "                  female, realism, greyhair, shorthair, shortchin, ponytail, blackhair,\n",
        "                  start_layer, end_layer):\n",
        "\n",
        "    scale = 1\n",
        "    seed, start_layer, end_layer = int(seed), int(start_layer), int(end_layer)\n",
        "    w = None\n",
        "    params = {'female': female,\n",
        "          'realism': realism,\n",
        "          'greyhair': greyhair,\n",
        "          'shorthair': shorthair,\n",
        "          'shortchin': shortchin,\n",
        "          'ponytail': ponytail,\n",
        "          'blackhair': blackhair}\n",
        "\n",
        "    param_indexes = {'female': 1,\n",
        "              'realism': 4,\n",
        "              'greyhair': 5,\n",
        "              'shorthair': 6,\n",
        "              'shortchin': 8,\n",
        "              'ponytail': 9,\n",
        "              'blackhair': 10}\n",
        "\n",
        "    directions = []\n",
        "    distances = []\n",
        "    for k, v in params.items():\n",
        "        directions.append(latent_dirs[param_indexes[k]])\n",
        "        distances.append(v)\n",
        "\n",
        "    model.truncation = truncation\n",
        "    if w is None:\n",
        "        w = model.sample_latent(1, seed=seed).detach().cpu().numpy()\n",
        "        w = [w]*model.get_max_latents() # one per layer\n",
        "    else:\n",
        "        w = [np.expand_dims(x, 0) for x in w]\n",
        "    \n",
        "\n",
        "    if directions != None and distances != None:\n",
        "        for l in range(start_layer, end_layer):\n",
        "          for i in range(len(directions)):\n",
        "            w[l] = w[l] + directions[i] * distances[i] * 1\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    final_im = Image.fromarray((out * 255).astype(np.uint8))\n",
        "    # final_im.save('/tmp/edit_output.jpg') # save the content to temp\n",
        "    \n",
        "    return final_im\n",
        "\n",
        "    #return display_sample_pytorch(int(seed), truncation, directions, distances, scale, int(start_layer), int(end_layer), disp=False)\n",
        "\n",
        "truncation = gr.inputs.Slider(minimum=0, maximum=1, default=0.5, label=\"Truncation\")\n",
        "start_layer = gr.inputs.Number(default=0, label=\"Start Layer\")\n",
        "end_layer = gr.inputs.Number(default=14, label=\"End Layer\")\n",
        "seed = gr.inputs.Number(default=0, label=\"Seed\")\n",
        "\n",
        "slider_max_val = 20\n",
        "slider_min_val = -20\n",
        "slider_step = 1\n",
        "\n",
        "female = gr.inputs.Slider(label=\"Female\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "realism = gr.inputs.Slider(label=\"Realism\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "greyhair = gr.inputs.Slider(label=\"Grey Hair\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "shorthair = gr.inputs.Slider(label=\"Short Hair\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "shortchin = gr.inputs.Slider(label=\"Short Chin\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "ponytail = gr.inputs.Slider(label=\"Ponytail\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "blackhair = gr.inputs.Slider(label=\"Black Hair\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "\n",
        "\n",
        "scale = 1\n",
        "\n",
        "inputs = [seed, truncation, female, realism, greyhair, shorthair, shortchin, ponytail, blackhair, start_layer, end_layer]\n",
        "\n",
        "gr.Interface(generate_image, inputs, \"image\", live=True, title=\"GAN Editing\").launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://29119.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://29119.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fa8e319f610>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7f3b9ee42a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfemale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreyhair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshorthair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortchin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mponytail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblackhair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GAN Editing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth, auth_message, private_endpoint, prevent_thread_lock)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ps1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprevent_thread_lock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_interactive_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR_VVuot7pn0",
        "outputId": "b1a6f8e6-838c-48f5-e391-b9cb7198a2d4"
      },
      "source": [
        "import hashlib\n",
        "seed = 'asds'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103889340637451552307951087327054883309227107387112946151010067908838645007837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "0DzGvutIfJdG",
        "outputId": "f09e56ea-14d4-42f9-ab81-f79608f1a450"
      },
      "source": [
        "#@title Character Gradio UI\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import hashlib\n",
        "\n",
        "def generate_image(seed, truncation,\n",
        "                  monster, female, skimpy, light, bodysuit, bulky, human_head,\n",
        "                  start_layer, end_layer):\n",
        "\n",
        "    scale = 1\n",
        "    seed = int(hashlib.sha256(seed.encode('utf-8')).hexdigest(), 16) % 10**8\n",
        "\n",
        "    params = {'monster': monster,\n",
        "          'female': female,\n",
        "          'skimpy': skimpy,\n",
        "          'light': light,\n",
        "          'bodysuit': bodysuit,\n",
        "          'bulky': bulky,\n",
        "          'human_head': human_head}\n",
        "\n",
        "    param_indexes = {'monster': 0,\n",
        "              'female': 1,\n",
        "              'skimpy': 2,\n",
        "              'light': 4,\n",
        "              'bodysuit': 5,\n",
        "              'bulky': 6,\n",
        "              'human_head': 8}\n",
        "\n",
        "    directions = []\n",
        "    distances = []\n",
        "    for k, v in params.items():\n",
        "        directions.append(latent_dirs[param_indexes[k]])\n",
        "        distances.append(v)\n",
        "\n",
        "    style = {'description_width': 'initial'}\n",
        "    return display_sample_pytorch(int(seed), truncation, directions, distances, scale, int(start_layer), int(end_layer), disp=False)\n",
        "\n",
        "truncation = gr.inputs.Slider(minimum=0, maximum=1, default=0.5, label=\"Truncation\")\n",
        "start_layer = gr.inputs.Number(default=0, label=\"Start Layer\")\n",
        "end_layer = gr.inputs.Number(default=14, label=\"End Layer\")\n",
        "seed = gr.inputs.Textbox(default='0')\n",
        "\n",
        "slider_max_val = 20\n",
        "slider_min_val = -20\n",
        "slider_step = 1\n",
        "\n",
        "monster = gr.inputs.Slider(label=\"Monster\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "female = gr.inputs.Slider(label=\"Female\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "skimpy = gr.inputs.Slider(label=\"Skimpy\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "light = gr.inputs.Slider(label=\"Light\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "bodysuit = gr.inputs.Slider(label=\"Bodysuit\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "bulky = gr.inputs.Slider(label=\"Bulky\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "human_head = gr.inputs.Slider(label=\"Human Head\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "\n",
        "\n",
        "scale = 1\n",
        "\n",
        "inputs = [seed, truncation, monster, female, skimpy, light, bodysuit, bulky, human_head, start_layer, end_layer]\n",
        "\n",
        "gr.Interface(generate_image, inputs, \"image\", live=True, title=\"CharacterGAN\").launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://53442.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://53442.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f06e619b510>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-546776d77710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfemale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskimpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbodysuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbulky\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CharacterGAN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth, auth_message, private_endpoint, prevent_thread_lock)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ps1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprevent_thread_lock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_interactive_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG0KVnIGfH5K"
      },
      "source": [
        "### FOMM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMmcGdYMDnyo",
        "cellView": "form"
      },
      "source": [
        "#@title Load Checkpoint for FOMM\n",
        "from demo import load_checkpoints\n",
        "import moviepy.editor as mpe\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "#!gdown --id 1jmcn19-c3p8mf39aYNXUhdMqzqDYZhQ_ -O vox-cpk.pth.tar\n",
        "\n",
        "generator, kp_detector = load_checkpoints(config_path='/content/drive/MyDrive/Colab/fyp/first-order-model/config/vox-256.yaml', \n",
        "                            checkpoint_path='/content/drive/MyDrive/Colab/fyp/first-order-model/vox-cpk.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O5jtu6_Ds8R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "outputId": "a4cbd547-ef3f-49ab-e366-dd9cfe9bb193"
      },
      "source": [
        "#@title FOMM UI\n",
        "import gradio as gr\n",
        "import moviepy.editor as mpe\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "def predict_video(image_path, video_path, relative, show_inputs,\n",
        "                  start_time=0, end_time=-1,\n",
        "                  center_video_to_head=True, crop_video_to_head=True, video_crop_expansion_factor=1.5,\n",
        "                  center_image_to_head=True, crop_image_to_head=True, image_crop_expansion_factor=2.5,\n",
        "                  speech=\"\", speaker='p225'):\n",
        "  \n",
        "    video_crop_expansion_factor = max(video_crop_expansion_factor, 1)\n",
        "    image_crop_expansion_factor = max(image_crop_expansion_factor, 1)\n",
        "\n",
        "    if end_time > start_time:\n",
        "        # cut video\n",
        "        print('Cutting Video...')\n",
        "        ffmpeg_extract_subclip(video_path, start_time, end_time, targetname='cut.mp4')\n",
        "        video_path = 'cut.mp4'\n",
        "\n",
        "    source_image = imageio.imread(image_path.name)\n",
        "    reader = imageio.get_reader(video_path)\n",
        "\n",
        "    source_image = pad_crop_resize(source_image, *get_crop(source_image, center_face=center_image_to_head, crop_face=crop_image_to_head, expansion_factor=image_crop_expansion_factor))\n",
        "    fps = reader.get_meta_data()['fps']\n",
        "    print('FPS', fps)\n",
        "    #fps = 8\n",
        "\n",
        "    driving_video = []\n",
        "    landmarks = None\n",
        "    try:\n",
        "        for i,im in enumerate(reader):\n",
        "            if not crop_video_to_head:\n",
        "                break\n",
        "            landmarks = fa.get_landmarks_from_image(im)\n",
        "            if landmarks:\n",
        "                break\n",
        "        x0,x1,y0,y1 = get_crop(im, center_face=center_video_to_head, crop_face=crop_video_to_head, expansion_factor=video_crop_expansion_factor, landmarks=landmarks)\n",
        "        reader.set_image_index(0)\n",
        "        for im in reader:\n",
        "            driving_video.append(pad_crop_resize(im,x0,x1,y0,y1))\n",
        "    except RuntimeError:\n",
        "        pass\n",
        "\n",
        "    # Generate animation\n",
        "    predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=relative)\n",
        "\n",
        "    fig = plt.figure(figsize=(10 * show_inputs + 8 * (predictions is not None), 8))\n",
        "\n",
        "    ims = []\n",
        "    for i in range(len(driving_video)):\n",
        "        cols = []\n",
        "        if show_inputs and speech == \"\":\n",
        "            cols.append(source_image)\n",
        "            cols.append(driving_video[i])\n",
        "        if predictions is not None:\n",
        "            cols.append(predictions[i])\n",
        "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
        "        plt.axis('off')\n",
        "        ims.append([im])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
        "    ani.save('output.mp4', fps=fps)\n",
        "    plt.close()\n",
        "\n",
        "    if speech != \"\":\n",
        "        !tts --text \"{speech}\" --out_path speech.wav --model_name \"tts_models/en/vctk/sc-glow-tts\"  --speaker_idx {speaker}\n",
        "        !cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../output.mp4\" --audio '../speech.wav'\n",
        "        return 'Wav2Lip/results/result_voice.mp4'\n",
        "    else:\n",
        "        video_clip = mpe.VideoFileClip('output.mp4')\n",
        "        audio_clip = mpe.AudioFileClip(video_path)\n",
        "        final_clip = video_clip.set_audio(audio_clip)\n",
        "        final_clip.write_videofile(\"result.mp4\", fps=fps)\n",
        "        return 'result.mp4'\n",
        "\n",
        "image_input = gr.inputs.Image(type=\"file\")\n",
        "video_input = gr.inputs.Video(type=\"mp4\")\n",
        "relative = gr.inputs.Checkbox(default=True, label=\"Relative\")\n",
        "show_inputs = gr.inputs.Checkbox(default=True, label=\"Show Inputs\")\n",
        "start_time = gr.inputs.Number(default=0, label=\"Start Time\")\n",
        "end_time = gr.inputs.Number(default=-1, label=\"End Time\")\n",
        "center_video_to_head = gr.inputs.Checkbox(default=True, label=\"Center Video to Head\")\n",
        "crop_video_to_head = gr.inputs.Checkbox(default=True, label=\"Crop Video to Head\")\n",
        "video_crop_expansion_factor = gr.inputs.Number(default=2, label=\"Video Crop Expansion Factor\")\n",
        "center_image_to_head = gr.inputs.Checkbox(default=False, label=\"Center Image to Head\")\n",
        "crop_image_to_head = gr.inputs.Checkbox(default=False, label=\"Crop Image to Head\")\n",
        "image_crop_expansion_factor = gr.inputs.Number(default=2, label=\"Image Crop Expansion Factor\")\n",
        "speech = gr.inputs.Textbox(label=\"Text to Speech\", default=\"\")\n",
        "speaker = gr.inputs.Dropdown(default='p225', choices=['p225', 'p226', 'p227', 'p228', 'p229', 'p230', 'p231', 'p232', 'p233', 'p234', 'p261'])\n",
        "\n",
        "inputs = [image_input, video_input, relative, show_inputs, start_time, end_time,\n",
        "          center_video_to_head, crop_video_to_head, video_crop_expansion_factor,\n",
        "          center_image_to_head, crop_image_to_head, image_crop_expansion_factor,\n",
        "          speech, speaker]\n",
        "    \n",
        "gr.Interface(predict_video, inputs, \"video\", live=False, title=\"Facial Animation\").launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://41796.gradio.app\n",
            "Interface loading below...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://41796.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f154c635d90>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS 25.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 339/339 [00:31<00:00, 10.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video result.mp4.\n",
            "MoviePy - Writing audio in resultTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video result.mp4\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready result.mp4\n",
            "FPS 25.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 339/339 [00:32<00:00, 10.59it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video result.mp4.\n",
            "MoviePy - Writing audio in resultTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video result.mp4\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready result.mp4\n",
            "FPS 25.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 339/339 [00:32<00:00, 10.59it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video result.mp4.\n",
            "MoviePy - Writing audio in resultTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video result.mp4\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready result.mp4\n",
            "FPS 25.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 339/339 [00:31<00:00, 10.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video result.mp4.\n",
            "MoviePy - Writing audio in resultTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video result.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready result.mp4\n",
            "FPS 25.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 339/339 [00:32<00:00, 10.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video result.mp4.\n",
            "MoviePy - Writing audio in resultTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video result.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready result.mp4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-af786465d0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m           speech, speaker]\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"video\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Facial Animation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth, auth_message, private_endpoint, prevent_thread_lock)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ps1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprevent_thread_lock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_interactive_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzR0qLFXfMZb"
      },
      "source": [
        "### Impersonator++"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yOfh0R7YGe5K",
        "cellView": "form",
        "outputId": "dc1f1667-bb26-4e6d-bd77-465f7cec950e"
      },
      "source": [
        "#@title Impersonator++ Gradio UI\n",
        "import gradio as gr\n",
        "import os.path as osp\n",
        "import platform\n",
        "import argparse\n",
        "import time\n",
        "import sys\n",
        "import subprocess\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "\n",
        "def imitate(im, video, bg_image, background, \n",
        "                   center_image_to_body, crop_image_to_body, image_crop_expansion_factor, keep_aspect_background, show_inputs, pose_fc, cam_fc):\n",
        "    source_image = imageio.imread(im.name)\n",
        "    source_image = pad_crop_resize(source_image, *get_crop_body(source_image, center_body=center_image_to_body, crop_body=crop_image_to_body, expansion_factor=image_crop_expansion_factor), new_h=800, new_w=800)\n",
        "    imageio.imwrite('/content/crop.png', (source_image*255).astype(np.uint8))\n",
        "\n",
        "    if bg_image != 'None':\n",
        "        bg_image = imageio.imread(bg_image.name)\n",
        "        bg_image = crop_resize(bg_image/255, source_image.shape[:2], crop=keep_aspect_background)\n",
        "        imageio.imwrite('/content/bg_crop.png', (bg_image*255).astype(np.uint8))\n",
        "    \n",
        "    with imageio.get_reader(video, format='mp4') as reader:\n",
        "        fps = reader.get_meta_data()['fps']\n",
        "    \n",
        "    gpu_ids = \"0\"\n",
        "    num_source = 1\n",
        "    assets_dir = \"/content/drive/MyDrive/Colab/fyp/iPERCore/assets\"\n",
        "    output_dir = \"/content/drive/MyDrive/Colab/fyp/iPERCore/results\"\n",
        "    shutil.rmtree(output_dir, ignore_errors=True)\n",
        "\n",
        "    # symlink from the actual assets directory to this current directory\n",
        "    work_asserts_dir = os.path.join(\"./assets\")\n",
        "    if not os.path.exists(work_asserts_dir):\n",
        "        os.symlink(osp.abspath(assets_dir), osp.abspath(work_asserts_dir),\n",
        "                  target_is_directory=(platform.system() == \"Windows\"))\n",
        "\n",
        "    cfg_path = osp.join(work_asserts_dir, \"configs\", \"deploy.toml\")\n",
        "\n",
        "    model_id = \"mymodel\"\n",
        "    \n",
        "    src_path = \"\\\"path?=/content/crop.png,name?=mymodel\"\n",
        "    if background=='replace' and os.path.exists('/content/bg_crop.png'):\n",
        "      src_path += ',bg_path?=/content/bg_crop.png'\n",
        "    src_path += '\"'\n",
        "\n",
        "    ref_path = \"\\\"path?=%s,\"  \\\n",
        "             \"name?=myoutput,\" \\\n",
        "             \"pose_fc?=%d,\"\\\n",
        "             \"cam_fc?=%d,\"\\\n",
        "             \"fps?=%f\\\"\"%(video,pose_fc,cam_fc,fps)\n",
        "    options = ''\n",
        "    if background=='inpaint':\n",
        "        options += ' --use_inpaintor'\n",
        "    \n",
        "    !python -m iPERCore.services.run_imitator --gpu_ids $gpu_ids --num_source $num_source --image_size $image_size --output_dir $output_dir --model_id $model_id --cfg_path $cfg_path --src_path $src_path --ref_path $ref_path $options\n",
        "\n",
        "    if show_inputs:\n",
        "        return \"/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4\"\n",
        "    else:\n",
        "        result_dir = '/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput'\n",
        "        frames = [os.path.abspath(os.path.join(result_dir, p)) for p in os.listdir(result_dir) if p.endswith(('jpg', 'png'))]\n",
        "        frames.sort()\n",
        "\n",
        "        #fps = last_frame/10\n",
        "        clip = ImageSequenceClip(frames, fps = fps)\n",
        "\n",
        "        #import re\n",
        "        #output_file = re.compile('\\.png$').sub('.mp4', args.output)\n",
        "        clip.write_videofile('impersonator_output.mp4')\n",
        "        return 'impersonator_output.mp4'\n",
        "\n",
        "\n",
        "im = gr.inputs.Image(type=\"file\", label=\"Source Image\")\n",
        "bg_image = gr.inputs.Image(type=\"file\", label=\"Background Image\")\n",
        "background = gr.inputs.Radio(choices=['None', 'replace', 'inpaint'], label=\"Background\")\n",
        "center_image_to_body = gr.inputs.Checkbox(default=True, label=\"Center Image to Body\")\n",
        "crop_image_to_body = gr.inputs.Checkbox(default=False, label=\"Crop Image to Body\")\n",
        "image_crop_expansion_factor = gr.inputs.Number(default=1.05, label=\"Image Crop Expansion Factor\")\n",
        "keep_aspect_background = gr.inputs.Checkbox(default=True, label=\"Keep Background Aspect Ratio\")\n",
        "show_inputs = gr.inputs.Checkbox(default=False, label=\"Show Inputs\")\n",
        "pose_fc = gr.inputs.Number(default=300, label=\"Pose Smooth Factor\")\n",
        "cam_fc = gr.inputs.Number(default=100, label=\"Camera Smooth Factor\")\n",
        "\n",
        "inputs = [im, 'video', bg_image, background, \n",
        "          center_image_to_body, crop_image_to_body, image_crop_expansion_factor, keep_aspect_background, show_inputs, pose_fc, cam_fc]\n",
        "\n",
        "\n",
        "\n",
        "iface = gr.Interface(imitate, inputs, \"video\", live=False, title=\"Full Body Animation\")\n",
        "iface.launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://26129.gradio.app\n",
            "Interface loading below...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://26129.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fb487802350>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffprobe -show_entries stream=codec_type -of json /tmp/1dlz75bh.mp4.avi -loglevel error\n",
            "ffmpeg -y -i /tmp/1dlz75bh.mp4.avi -ab 160k -ac 2 -ar 44100 -vn /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3 -loglevel quiet\n",
            "ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate /tmp/1dlz75bh.mp4.avi\n",
            "\tPre-processing: start...\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /content/crop.png\n",
            "\tbg_path: \n",
            "\tname: mymodel\n",
            "primitives_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel\n",
            "processed_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed\n",
            "vid_info_path: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /tmp/1dlz75bh.mp4.avi\n",
            "\tbg_path: \n",
            "\tname: myoutput\n",
            "\taudio: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3\n",
            "\tfps: 30.0\n",
            "\tpose_fc: 300.0\n",
            "\tcam_fc: 100.0\n",
            "\teffect: \n",
            "primitives_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput\n",
            "processed_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed\n",
            "vid_info_path: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "None\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images...\n",
            "100% 1/1 [00:00<00:00,  3.58it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images by estimated boxes ...\n",
            "1it [00:00, 16.40it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "100% 1/1 [00:00<00:00,  1.09it/s]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "\t1.4 Preprocessing, running Preprocessor to run human matting in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/parse ... \n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "100% 1/1 [00:00<00:00,  1.75it/s]\n",
            "\t1.4 Preprocessing, finish run human matting.\n",
            "\t1.5 Preprocessing, running Preprocessor to find 25 candidates front images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "100% 1/1 [00:00<00:00, 13.34it/s]\n",
            "\t1.5 Preprocessing, finish find the front images ....\n",
            "\t1.6 Preprocessing, running Preprocessor to run background inpainting ...\n",
            "100% 1/1 [00:02<00:00,  2.95s/it]\n",
            "\t1.6 Preprocessing, finish run background inpainting ....\n",
            "\t1.7 Preprocessing, saving visualization to /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 ...\n",
            "100% 1/1 [00:02<00:00,  2.35s/it]\n",
            "ffmpeg -y -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4.avi -vcodec h264 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 -loglevel quiet\n",
            "\t1.7 Preprocessing, saving visualization to /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 ...\n",
            "Preprocessor has finished...\n",
            "/tmp/1dlz75bh.mp4.avi Writing frames to file\n",
            "ffmpeg -i /tmp/1dlz75bh.mp4.avi -start_number 0 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images/frame_%08d.png\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, avi, from '/tmp/1dlz75bh.mp4.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:11.27, start: 0.000000, bitrate: 539 kb/s\n",
            "    Stream #0:0: Video: mpeg4 (Simple Profile) (FMP4 / 0x34504D46), yuv420p, 800x800 [SAR 1:1 DAR 1:1], 392 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "    Stream #0:1: Audio: mp3 (U[0][0][0] / 0x0055), 48000 Hz, stereo, s16p, 128 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mpeg4 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images/frame_%08d.png':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: png, rgb24, 800x800 [SAR 1:1 DAR 1:1], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame=  338 fps= 39 q=-0.0 Lsize=N/A time=00:00:11.26 bitrate=N/A dup=2 drop=0 speed= 1.3x    \n",
            "video:48888kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images...\n",
            "100% 338/338 [01:09<00:00,  4.88it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images by estimated boxes ...\n",
            "338it [00:07, 46.47it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/images ...\n",
            "100% 11/11 [00:15<00:00,  1.38s/it]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "Preprocessor has finished...\n",
            "\t\tPre-processing: digital deformation start...\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "\t\tPre-processing: digital deformation completed...\n",
            "the current number of sources are 1, while the pre-defined number of sources are 1. \n",
            "\tPre-processing: successfully...\n",
            "Step 2: running personalization on\n",
            "#train video clips = 1\n",
            "  0% 0/100 [00:00<?, ?it/s]Network AttLWB-SPADE was created\n",
            "Network patch_global was created\n",
            "Loading vgg19 from ./assets/checkpoints/losses/vgg19-dcbb9e9d.pth...\n",
            "Loading face model from ./assets/checkpoints/losses/sphere20a_20171020.pth\n",
            "Loading net: ./assets/checkpoints/neural_renders/AttLWB-SPADE_id_G_2020-05-18.pth\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "100% 100/100 [04:44<00:00,  2.84s/it]\n",
            "saving the personalized model in /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth\n",
            "Step 2: personalization done, saved in /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth...\n",
            "Step 3: running imitator.\n",
            "Network AttLWB-SPADE was created\n",
            "Loading net from /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth\n",
            "Model Imitator was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "pred_: 100% 338/338 [02:38<00:00,  2.14it/s]\n",
            "338it [00:08, 39.66it/s]\n",
            "ffmpeg -y -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4.avi -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3 -vcodec h264 -shortest -strict -2 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4 -loglevel quiet\n",
            "----------------------MetaOutput----------------------\n",
            "mymodel imitates myoutput in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4\n",
            "------------------------------------------------------\n",
            "Step 3: running imitator done.\n",
            "Moviepy - Building video impersonator_output.mp4.\n",
            "Moviepy - Writing video impersonator_output.mp4\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready impersonator_output.mp4\n",
            "ffprobe -show_entries stream=codec_type -of json /tmp/ba6rbn7o.mp4.avi -loglevel error\n",
            "ffmpeg -y -i /tmp/ba6rbn7o.mp4.avi -ab 160k -ac 2 -ar 44100 -vn /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3 -loglevel quiet\n",
            "ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate /tmp/ba6rbn7o.mp4.avi\n",
            "\tPre-processing: start...\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /content/crop.png\n",
            "\tbg_path: /content/bg_crop.png\n",
            "\tname: mymodel\n",
            "primitives_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel\n",
            "processed_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed\n",
            "vid_info_path: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /tmp/ba6rbn7o.mp4.avi\n",
            "\tbg_path: \n",
            "\tname: myoutput\n",
            "\taudio: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3\n",
            "\tfps: 30.0\n",
            "\tpose_fc: 300.0\n",
            "\tcam_fc: 100.0\n",
            "\teffect: \n",
            "primitives_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput\n",
            "processed_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed\n",
            "vid_info_path: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "None\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images...\n",
            "100% 1/1 [00:00<00:00,  3.45it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images by estimated boxes ...\n",
            "1it [00:00, 16.54it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "\t1.4 Preprocessing, running Preprocessor to run human matting in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/parse ... \n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "100% 1/1 [00:00<00:00,  1.62it/s]\n",
            "\t1.4 Preprocessing, finish run human matting.\n",
            "\t1.5 Preprocessing, running Preprocessor to find 25 candidates front images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "100% 1/1 [00:00<00:00, 13.44it/s]\n",
            "\t1.5 Preprocessing, finish find the front images ....\n",
            "\t1.6 Preprocessing, running Preprocessor to run background inpainting ...\n",
            "100% 1/1 [00:02<00:00,  2.95s/it]\n",
            "\t1.6 Preprocessing, finish run background inpainting ....\n",
            "\t1.7 Preprocessing, saving visualization to /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 ...\n",
            "100% 1/1 [00:02<00:00,  2.34s/it]\n",
            "ffmpeg -y -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4.avi -vcodec h264 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 -loglevel quiet\n",
            "\t1.7 Preprocessing, saving visualization to /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 ...\n",
            "Preprocessor has finished...\n",
            "/tmp/ba6rbn7o.mp4.avi Writing frames to file\n",
            "ffmpeg -i /tmp/ba6rbn7o.mp4.avi -start_number 0 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images/frame_%08d.png\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, avi, from '/tmp/ba6rbn7o.mp4.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:11.33, start: 0.000000, bitrate: 561 kb/s\n",
            "    Stream #0:0: Video: mpeg4 (Simple Profile) (FMP4 / 0x34504D46), yuv420p, 800x800 [SAR 1:1 DAR 1:1], 414 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "    Stream #0:1: Audio: mp3 (U[0][0][0] / 0x0055), 48000 Hz, stereo, s16p, 128 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mpeg4 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images/frame_%08d.png':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: png, rgb24, 800x800 [SAR 1:1 DAR 1:1], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame=  340 fps= 41 q=-0.0 Lsize=N/A time=00:00:11.33 bitrate=N/A dup=2 drop=0 speed=1.38x    \n",
            "video:48254kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images...\n",
            "100% 340/340 [01:10<00:00,  4.83it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images by estimated boxes ...\n",
            "340it [00:07, 46.16it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/images ...\n",
            "100% 11/11 [00:14<00:00,  1.34s/it]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "Preprocessor has finished...\n",
            "\t\tPre-processing: digital deformation start...\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "\t\tPre-processing: digital deformation completed...\n",
            "the current number of sources are 1, while the pre-defined number of sources are 1. \n",
            "\tPre-processing: successfully...\n",
            "Step 2: running personalization on\n",
            "#train video clips = 1\n",
            "  0% 0/100 [00:00<?, ?it/s]Network AttLWB-SPADE was created\n",
            "Network patch_global was created\n",
            "Loading vgg19 from ./assets/checkpoints/losses/vgg19-dcbb9e9d.pth...\n",
            "Loading face model from ./assets/checkpoints/losses/sphere20a_20171020.pth\n",
            "Loading net: ./assets/checkpoints/neural_renders/AttLWB-SPADE_id_G_2020-05-18.pth\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "100% 100/100 [05:10<00:00,  3.10s/it]\n",
            "saving the personalized model in /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth\n",
            "Step 2: personalization done, saved in /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth...\n",
            "Step 3: running imitator.\n",
            "Network AttLWB-SPADE was created\n",
            "Loading net from /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth\n",
            "Model Imitator was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "pred_: 100% 340/340 [02:37<00:00,  2.16it/s]\n",
            "340it [00:08, 42.24it/s]\n",
            "ffmpeg -y -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4.avi -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3 -vcodec h264 -shortest -strict -2 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4 -loglevel quiet\n",
            "----------------------MetaOutput----------------------\n",
            "mymodel imitates myoutput in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4\n",
            "------------------------------------------------------\n",
            "Step 3: running imitator done.\n",
            "Moviepy - Building video impersonator_output.mp4.\n",
            "Moviepy - Writing video impersonator_output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready impersonator_output.mp4\n",
            "ffprobe -show_entries stream=codec_type -of json /tmp/9r4llhjb.mp4.avi -loglevel error\n",
            "ffmpeg -y -i /tmp/9r4llhjb.mp4.avi -ab 160k -ac 2 -ar 44100 -vn /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3 -loglevel quiet\n",
            "ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate /tmp/9r4llhjb.mp4.avi\n",
            "\tPre-processing: start...\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /content/crop.png\n",
            "\tbg_path: /content/bg_crop.png\n",
            "\tname: mymodel\n",
            "primitives_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel\n",
            "processed_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed\n",
            "vid_info_path: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /tmp/9r4llhjb.mp4.avi\n",
            "\tbg_path: \n",
            "\tname: myoutput\n",
            "\taudio: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3\n",
            "\tfps: 30.0\n",
            "\tpose_fc: 300.0\n",
            "\tcam_fc: 100.0\n",
            "\teffect: \n",
            "primitives_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput\n",
            "processed_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed\n",
            "vid_info_path: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "None\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images...\n",
            "100% 1/1 [00:00<00:00,  3.63it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images by estimated boxes ...\n",
            "1it [00:00, 17.84it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "100% 1/1 [00:00<00:00,  1.21it/s]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "\t1.4 Preprocessing, running Preprocessor to run human matting in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/parse ... \n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "100% 1/1 [00:00<00:00,  1.69it/s]\n",
            "\t1.4 Preprocessing, finish run human matting.\n",
            "\t1.5 Preprocessing, running Preprocessor to find 25 candidates front images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "100% 1/1 [00:00<00:00, 13.52it/s]\n",
            "\t1.5 Preprocessing, finish find the front images ....\n",
            "\t1.6 Preprocessing, running Preprocessor to run background inpainting ...\n",
            "100% 1/1 [00:02<00:00,  2.99s/it]\n",
            "\t1.6 Preprocessing, finish run background inpainting ....\n",
            "\t1.7 Preprocessing, saving visualization to /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 ...\n",
            "100% 1/1 [00:02<00:00,  2.37s/it]\n",
            "ffmpeg -y -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4.avi -vcodec h264 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 -loglevel quiet\n",
            "\t1.7 Preprocessing, saving visualization to /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 ...\n",
            "Preprocessor has finished...\n",
            "/tmp/9r4llhjb.mp4.avi Writing frames to file\n",
            "ffmpeg -i /tmp/9r4llhjb.mp4.avi -start_number 0 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images/frame_%08d.png\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, avi, from '/tmp/9r4llhjb.mp4.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:04.40, start: 0.000000, bitrate: 965 kb/s\n",
            "    Stream #0:0: Video: mpeg4 (Simple Profile) (FMP4 / 0x34504D46), yuv420p, 1600x900 [SAR 1:1 DAR 16:9], 815 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "    Stream #0:1: Audio: mp3 (U[0][0][0] / 0x0055), 48000 Hz, stereo, s16p, 128 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mpeg4 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images/frame_%08d.png':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: png, rgb24, 1600x900 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame=  132 fps= 26 q=-0.0 Lsize=N/A time=00:00:04.40 bitrate=N/A dup=2 drop=0 speed=0.863x    \n",
            "video:21990kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images...\n",
            "100% 132/132 [00:46<00:00,  2.86it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images by estimated boxes ...\n",
            "132it [00:03, 38.48it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/images ...\n",
            "100% 5/5 [00:07<00:00,  1.44s/it]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "Preprocessor has finished...\n",
            "\t\tPre-processing: digital deformation start...\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "\t\tPre-processing: digital deformation completed...\n",
            "the current number of sources are 1, while the pre-defined number of sources are 1. \n",
            "\tPre-processing: successfully...\n",
            "Step 2: running personalization on\n",
            "#train video clips = 1\n",
            "  0% 0/100 [00:00<?, ?it/s]Network AttLWB-SPADE was created\n",
            "Network patch_global was created\n",
            "Loading vgg19 from ./assets/checkpoints/losses/vgg19-dcbb9e9d.pth...\n",
            "Loading face model from ./assets/checkpoints/losses/sphere20a_20171020.pth\n",
            "Loading net: ./assets/checkpoints/neural_renders/AttLWB-SPADE_id_G_2020-05-18.pth\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "100% 100/100 [04:46<00:00,  2.87s/it]\n",
            "saving the personalized model in /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth\n",
            "Step 2: personalization done, saved in /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth...\n",
            "Step 3: running imitator.\n",
            "Network AttLWB-SPADE was created\n",
            "Loading net from /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth\n",
            "Model Imitator was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "pred_: 100% 132/132 [01:01<00:00,  2.15it/s]\n",
            "132it [00:03, 40.09it/s]\n",
            "ffmpeg -y -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4.avi -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3 -vcodec h264 -shortest -strict -2 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4 -loglevel quiet\n",
            "----------------------MetaOutput----------------------\n",
            "mymodel imitates myoutput in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4\n",
            "------------------------------------------------------\n",
            "Step 3: running imitator done.\n",
            "Moviepy - Building video impersonator_output.mp4.\n",
            "Moviepy - Writing video impersonator_output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready impersonator_output.mp4\n",
            "ffprobe -show_entries stream=codec_type -of json /tmp/zvq5qdu2.mp4.avi -loglevel error\n",
            "ffmpeg -y -i /tmp/zvq5qdu2.mp4.avi -ab 160k -ac 2 -ar 44100 -vn /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3 -loglevel quiet\n",
            "ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate /tmp/zvq5qdu2.mp4.avi\n",
            "\tPre-processing: start...\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /content/crop.png\n",
            "\tbg_path: \n",
            "\tname: mymodel\n",
            "primitives_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel\n",
            "processed_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed\n",
            "vid_info_path: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /tmp/zvq5qdu2.mp4.avi\n",
            "\tbg_path: \n",
            "\tname: myoutput\n",
            "\taudio: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3\n",
            "\tfps: 30.0\n",
            "\tpose_fc: 300.0\n",
            "\tcam_fc: 100.0\n",
            "\teffect: \n",
            "primitives_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput\n",
            "processed_dir: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed\n",
            "vid_info_path: /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "None\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images...\n",
            "100% 1/1 [00:00<00:00,  3.53it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/orig_images by estimated boxes ...\n",
            "1it [00:00, 20.03it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "100% 1/1 [00:00<00:00,  1.08it/s]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "\t1.4 Preprocessing, running Preprocessor to run human matting in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/parse ... \n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "100% 1/1 [00:00<00:00,  1.75it/s]\n",
            "\t1.4 Preprocessing, finish run human matting.\n",
            "\t1.5 Preprocessing, running Preprocessor to find 25 candidates front images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/images ...\n",
            "100% 1/1 [00:00<00:00, 13.55it/s]\n",
            "\t1.5 Preprocessing, finish find the front images ....\n",
            "\t1.6 Preprocessing, running Preprocessor to run background inpainting ...\n",
            "100% 1/1 [00:02<00:00,  2.94s/it]\n",
            "\t1.6 Preprocessing, finish run background inpainting ....\n",
            "\t1.7 Preprocessing, saving visualization to /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 ...\n",
            "100% 1/1 [00:02<00:00,  2.36s/it]\n",
            "ffmpeg -y -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4.avi -vcodec h264 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 -loglevel quiet\n",
            "\t1.7 Preprocessing, saving visualization to /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/processed/visual.mp4 ...\n",
            "Preprocessor has finished...\n",
            "/tmp/zvq5qdu2.mp4.avi Writing frames to file\n",
            "ffmpeg -i /tmp/zvq5qdu2.mp4.avi -start_number 0 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images/frame_%08d.png\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, avi, from '/tmp/zvq5qdu2.mp4.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:04.40, start: 0.000000, bitrate: 965 kb/s\n",
            "    Stream #0:0: Video: mpeg4 (Simple Profile) (FMP4 / 0x34504D46), yuv420p, 1600x900 [SAR 1:1 DAR 16:9], 815 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "    Stream #0:1: Audio: mp3 (U[0][0][0] / 0x0055), 48000 Hz, stereo, s16p, 128 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mpeg4 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images/frame_%08d.png':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: png, rgb24, 1600x900 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame=  132 fps= 26 q=-0.0 Lsize=N/A time=00:00:04.40 bitrate=N/A dup=2 drop=0 speed=0.876x    \n",
            "video:21990kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images...\n",
            "100% 132/132 [00:45<00:00,  2.89it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/orig_images by estimated boxes ...\n",
            "132it [00:03, 39.48it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in/content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/images ...\n",
            "100% 5/5 [00:06<00:00,  1.29s/it]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "Preprocessor has finished...\n",
            "\t\tPre-processing: digital deformation start...\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "\t\tPre-processing: digital deformation completed...\n",
            "the current number of sources are 1, while the pre-defined number of sources are 1. \n",
            "\tPre-processing: successfully...\n",
            "Step 2: running personalization on\n",
            "#train video clips = 1\n",
            "  0% 0/100 [00:00<?, ?it/s]Network AttLWB-SPADE was created\n",
            "Network patch_global was created\n",
            "Loading vgg19 from ./assets/checkpoints/losses/vgg19-dcbb9e9d.pth...\n",
            "Loading face model from ./assets/checkpoints/losses/sphere20a_20171020.pth\n",
            "Loading net: ./assets/checkpoints/neural_renders/AttLWB-SPADE_id_G_2020-05-18.pth\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "100% 100/100 [04:42<00:00,  2.83s/it]\n",
            "saving the personalized model in /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth\n",
            "Step 2: personalization done, saved in /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth...\n",
            "Step 3: running imitator.\n",
            "Network AttLWB-SPADE was created\n",
            "Loading net from /content/drive/MyDrive/Colab/fyp/iPERCore/results/models/mymodel/personalized.pth\n",
            "Model Imitator was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "pred_: 100% 132/132 [01:01<00:00,  2.14it/s]\n",
            "132it [00:03, 40.76it/s]\n",
            "ffmpeg -y -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4.avi -i /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/myoutput/processed/audio.mp3 -vcodec h264 -shortest -strict -2 /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4 -loglevel quiet\n",
            "----------------------MetaOutput----------------------\n",
            "mymodel imitates myoutput in /content/drive/MyDrive/Colab/fyp/iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4\n",
            "------------------------------------------------------\n",
            "Step 3: running imitator done.\n",
            "Moviepy - Building video impersonator_output.mp4.\n",
            "Moviepy - Writing video impersonator_output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready impersonator_output.mp4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-87bf7964192c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0miface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimitate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"video\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Full Body Animation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth, auth_message, private_endpoint, prevent_thread_lock)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ps1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprevent_thread_lock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_interactive_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mUwHxVFTDEg"
      },
      "source": [
        "\n",
        "## Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "krm-eciaTx5M",
        "outputId": "805bc540-115d-4eef-8517-a69272bc2ded"
      },
      "source": [
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n",
        "\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn aiofiles python-multipart firebase-admin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 200})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.67.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.0.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.7/dist-packages (0.0.5)\n",
            "Requirement already satisfied: firebase-admin in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: starlette==0.14.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.14.2)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n",
            "Requirement already satisfied: click>=7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.7.4.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (0.12.0)\n",
            "Requirement already satisfied: asgiref>=3.3.4 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.4.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from python-multipart) (1.15.0)\n",
            "Requirement already satisfied: cachecontrol>=0.12.6 in /usr/local/lib/python3.7/dist-packages (from firebase-admin) (0.12.6)\n",
            "Requirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.7/dist-packages (from firebase-admin) (1.12.8)\n",
            "Requirement already satisfied: google-cloud-storage>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from firebase-admin) (1.18.1)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\" in /usr/local/lib/python3.7/dist-packages (from firebase-admin) (1.26.3)\n",
            "Requirement already satisfied: google-cloud-firestore>=1.4.0; platform_python_implementation != \"PyPy\" in /usr/local/lib/python3.7/dist-packages (from firebase-admin) (1.7.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from cachecontrol>=0.12.6->firebase-admin) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cachecontrol>=0.12.6->firebase-admin) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (1.32.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.17.4)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage>=1.18.0->firebase-admin) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage>=1.18.0->firebase-admin) (0.4.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase-admin) (21.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase-admin) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase-admin) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase-admin) (1.53.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase-admin) (57.2.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0; extra == \"grpc\" in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase-admin) (1.34.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.7.8->firebase-admin) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.7.8->firebase-admin) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.7.8->firebase-admin) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase-admin) (2.4.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth>=1.16.0->google-api-python-client>=1.7.8->firebase-admin) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXYdqPx18Iv0"
      },
      "source": [
        "firebase_admin.delete_app(firebase_admin.get_app())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n4mDrn_UBO5",
        "cellView": "form"
      },
      "source": [
        "#@title API Functions\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import FileResponse, StreamingResponse\n",
        "from fastapi import FastAPI, File, UploadFile, Form\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, Dict, List\n",
        "from io import StringIO, BytesIO\n",
        "from pydantic import BaseModel\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore, storage\n",
        "\n",
        "# Use the application default credentials\n",
        "if not firebase_admin._apps:\n",
        "    cred = credentials.Certificate(\"/content/drive/MyDrive/Colab/fyp/gancreate-firebase-adminsdk-yayqe-07b54a912d.json\")\n",
        "    firebase_admin.initialize_app(cred, {\n",
        "        'storageBucket': 'gancreate.appspot.com'\n",
        "    })\n",
        "\n",
        "db = firestore.client()\n",
        "bucket = storage.bucket()\n",
        "\n",
        "\n",
        "# Log the user in\n",
        "user = \"YyzhczpqEzMw6uWHuikt0Icg2Sp1\"\n",
        "\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get('/')\n",
        "async def root():\n",
        "    return {'hello': 'world'}\n",
        "\n",
        "def sample(seed: int = None, truncation: float = 0.5, w=None):\n",
        "    model.truncation = truncation\n",
        "    if w is None:\n",
        "        w = model.sample_latent(1, seed=seed).detach().cpu().numpy()\n",
        "        w = [w]*model.get_max_latents() # one per layer\n",
        "  \n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    return Image.fromarray((out * 255).astype(np.uint8))\n",
        "\n",
        "@app.get('/generate')\n",
        "async def generate(model_type: str = 'portrait', seed: int = None, truncation: float = 0.5, w=None, save=False):\n",
        "    if config.output_class != model_type:\n",
        "        load_model(model_type)\n",
        "    model.truncation = truncation\n",
        "    if w is None:\n",
        "        w = model.sample_latent(1, seed=seed).detach().cpu().numpy()\n",
        "        w = [w]*model.get_max_latents() # one per layer\n",
        "  \n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    final_im = Image.fromarray((out * 255).astype(np.uint8))\n",
        "    \n",
        "    final_im.save('/tmp/output.jpg') # save the content to temp\n",
        "    \n",
        "    return FileResponse('/tmp/output.jpg', media_type=\"image/jpeg\")\n",
        "\n",
        "class EditConfig(BaseModel):\n",
        "    model_type: Optional[str] = \"portrait\" \n",
        "    seed: Optional[int] = None\n",
        "    truncation: Optional[float] = 0.5\n",
        "    start_layer: Optional[int] = 0\n",
        "    end_layer: Optional[int] = 14\n",
        "    attributes: Dict[str, float]\n",
        "    latent_id: Optional[str] = \"\"\n",
        "    save: Optional[bool] = False\n",
        "\n",
        "@app.post('/edit')\n",
        "async def edit(edit_config: EditConfig):\n",
        "    model_type = edit_config.model_type\n",
        "    if config.output_class != model_type:\n",
        "        load_model(model_type)\n",
        "\n",
        "    seed = edit_config.seed        \n",
        "    latent_id = edit_config.latent_id\n",
        "    model.truncation = edit_config.truncation\n",
        "    if latent_id is None or latent_id is \"\":\n",
        "        w = model.sample_latent(1, seed=seed).detach().cpu().numpy()\n",
        "        w = [w]*model.get_max_latents() # one per layer\n",
        "    else:\n",
        "        w = np.load(f\"latents/{model_type}/{latent_id}.npy\")\n",
        "        w = [np.expand_dims(x, 0) for x in w]\n",
        "    \n",
        "    param_indexes = {\n",
        "        \"portrait\": {\n",
        "            'Gender': 1,\n",
        "            'Realism': 4,\n",
        "            'Gray Hair': 5,\n",
        "            'Hair Length': 6,\n",
        "            'Chin': 8,\n",
        "            'Ponytail': 9,\n",
        "            'Black Hair': 10\n",
        "        },\n",
        "        \"model\": {\n",
        "            'Gender': 4,\n",
        "            'Dress': 0,\n",
        "            'Sleveeless': 1,\n",
        "            'Short Skirt': 3,\n",
        "            'Jacket': 5,\n",
        "            'Darkness': 7,\n",
        "            'Slimness': 9\n",
        "        },\n",
        "        \"character\": {\n",
        "            'Monster': 0,\n",
        "            'Gender': 1,\n",
        "            'Skimpiness': 2,\n",
        "            'Light': 4,\n",
        "            'Bodysuit': 5,\n",
        "            'Bulkiness': 6,\n",
        "            'Human Head': 8\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    directions = []\n",
        "    distances = []\n",
        "    for k, v in edit_config.attributes.items():\n",
        "        directions.append(latent_dirs[param_indexes[model_type][k]])\n",
        "        distances.append(v)\n",
        "\n",
        "    if directions != None and distances != None:\n",
        "        for l in range(edit_config.start_layer, edit_config.end_layer):\n",
        "          for i in range(len(directions)):\n",
        "            w[l] = w[l] + directions[i] * distances[i] * 1\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    final_im = Image.fromarray((out * 255).astype(np.uint8))\n",
        "    final_im.save('/tmp/edit_output.jpg') # save the content to temp\n",
        "\n",
        "    if edit_config.save:\n",
        "        doc_ref = db.collection(f'{model_type}s').add({})\n",
        "        doc_id = doc_ref[1].id\n",
        "        \n",
        "        blob = bucket.blob(f'{model_type}s/{doc_id}.jpg')\n",
        "        blob.upload_from_filename('/tmp/edit_output.jpg')\n",
        "        blob.make_public()\n",
        "\n",
        "        data = {\n",
        "            \"url\": blob.public_url,\n",
        "            \"user\": user,\n",
        "            \"created_at\": datetime.datetime.now()\n",
        "        }\n",
        "        db.collection(f'{model_type}s').document(doc_id).set(data)\n",
        "        np.save(f'latents/{model_type}/{doc_id}.npy', w)\n",
        "\n",
        "    return FileResponse('/tmp/edit_output.jpg', media_type=\"image/jpeg\")\n",
        "\n",
        "class AnimateFaceConfig(BaseModel):\n",
        "    center_video_to_head: Optional[bool] = True\n",
        "    crop_video_to_head: Optional[bool] = True\n",
        "    center_image_to_head: Optional[bool] = True\n",
        "    center_video_to_head: Optional[bool] = True\n",
        "    video_crop_expansion_factor: Optional[float] = 1.5\n",
        "    image_crop_expansion_factor: Optional[float] = 2.5\n",
        "    speech: Optional[str] = \"\"\n",
        "    speaker: Optional[str] = \"p225\"\n",
        "    show_inputs: Optional[bool] = False\n",
        "\n",
        "\n",
        "\n",
        "@app.post(\"/animate/face\")\n",
        "async def animate_face(\n",
        "        files: List[UploadFile] = File(...),\n",
        "        center_video_to_head: bool = Form(True),\n",
        "        crop_video_to_head: bool = Form(True),\n",
        "        video_crop_expansion_factor: float = Form(1.5),\n",
        "        center_image_to_head: bool = Form(True),\n",
        "        crop_image_to_head: bool = Form(True),\n",
        "        image_crop_expansion_factor: float = Form(2.5),\n",
        "        relative: bool = Form(True),\n",
        "        speech: str = Form(\"\"),\n",
        "        speaker: str = Form(\"p225\"),\n",
        "        show_inputs: bool = Form(False),\n",
        "    ):\n",
        "  \n",
        "    video_crop_expansion_factor = max(video_crop_expansion_factor, 1)\n",
        "    image_crop_expansion_factor = max(image_crop_expansion_factor, 1)\n",
        "\n",
        "    source_image = files[0]\n",
        "    ref_video = files[1]\n",
        "\n",
        "    with open(source_image.filename, \"wb\") as buffer:\n",
        "        shutil.copyfileobj(source_image.file, buffer)\n",
        "\n",
        "    video_path = \"ref_video.mp4\"\n",
        "\n",
        "    with open(video_path, \"wb\") as buffer:\n",
        "        shutil.copyfileobj(ref_video.file, buffer)\n",
        "\n",
        "    source_image = imageio.imread(source_image.filename)\n",
        "    reader = imageio.get_reader(video_path)\n",
        "\n",
        "    source_image = pad_crop_resize(source_image, *get_crop(source_image, center_face=center_image_to_head, crop_face=crop_image_to_head, expansion_factor=image_crop_expansion_factor))\n",
        "    fps = reader.get_meta_data()['fps']\n",
        "\n",
        "    driving_video = []\n",
        "    landmarks = None\n",
        "    try:\n",
        "        for i,im in enumerate(reader):\n",
        "            if not crop_video_to_head:\n",
        "                break\n",
        "            landmarks = fa.get_landmarks_from_image(im)\n",
        "            if landmarks:\n",
        "                break\n",
        "        x0,x1,y0,y1 = get_crop(im, center_face=center_video_to_head, crop_face=crop_video_to_head, expansion_factor=video_crop_expansion_factor, landmarks=landmarks)\n",
        "        reader.set_image_index(0)\n",
        "        for im in reader:\n",
        "            driving_video.append(pad_crop_resize(im,x0,x1,y0,y1))\n",
        "    except RuntimeError:\n",
        "        pass\n",
        "\n",
        "    # Generate animation\n",
        "    predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=relative)\n",
        "\n",
        "    fig = plt.figure(figsize=(12 * show_inputs + 6 * (predictions is not None), 8))\n",
        "\n",
        "    ims = []\n",
        "    for i in range(len(driving_video)):\n",
        "        cols = []\n",
        "        if show_inputs and speech == \"\":\n",
        "            cols.append(source_image)\n",
        "            cols.append(driving_video[i])\n",
        "        if predictions is not None:\n",
        "            cols.append(predictions[i])\n",
        "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
        "        plt.axis('off')\n",
        "        ims.append([im])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
        "    ani.save('output.mp4', fps=fps)\n",
        "    plt.close()\n",
        "\n",
        "    if speech != \"\":\n",
        "        !tts --text \"{speech}\" --out_path speech.wav --model_name \"tts_models/en/vctk/sc-glow-tts\"  --speaker_idx {speaker}\n",
        "        !cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../output.mp4\" --audio '../speech.wav'\n",
        "        return FileResponse('Wav2Lip/results/result_voice.mp4', media_type=\"video/mp4\")\n",
        "    else:\n",
        "        video_clip = mpe.VideoFileClip('output.mp4')\n",
        "        audio_clip = mpe.AudioFileClip(video_path)\n",
        "        final_clip = video_clip.set_audio(audio_clip)\n",
        "        final_clip.write_videofile(\"result.mp4\", fps=fps)\n",
        "        return FileResponse('result.mp4', media_type=\"video/mp4\")\n",
        "\n",
        "@app.post(\"/animate/body\")\n",
        "async def animate_body(\n",
        "        files: List[UploadFile] = File(...),\n",
        "        background: str = Form(\"None\"),\n",
        "        center_image_to_body: bool = Form(True),\n",
        "        crop_image_to_body: bool = Form(False),\n",
        "        image_crop_expansion_factor: float = Form(1.05) ,\n",
        "        keep_aspect_background: bool = Form(True),\n",
        "        pose_fc: int = Form(300),\n",
        "        cam_fc: int = Form(100),\n",
        "    ):\n",
        "  \n",
        "    source_image = files[0]\n",
        "    ref_video = files[1]\n",
        "    bg_image = files[2]\n",
        "\n",
        "    with open(source_image.filename, \"wb\") as buffer:\n",
        "        shutil.copyfileobj(source_image.file, buffer)\n",
        "\n",
        "    video_path = \"ref_video.mp4\"\n",
        "\n",
        "    with open(video_path, \"wb\") as buffer:\n",
        "        shutil.copyfileobj(ref_video.file, buffer)\n",
        "    \n",
        "    source_image = imageio.imread(source_image.filename)\n",
        "    source_image = pad_crop_resize(source_image, *get_crop_body(source_image, center_body=center_image_to_body, crop_body=crop_image_to_body, expansion_factor=image_crop_expansion_factor))\n",
        "    imageio.imwrite('/content/crop.png', (source_image*255).astype(np.uint8))\n",
        "\n",
        "    if bg_image != 'None':\n",
        "        with open(bg_image.filename, \"wb\") as buffer:\n",
        "            shutil.copyfileobj(bg_image.file, buffer)\n",
        "        bg_image = imageio.imread(bg_image.filename)\n",
        "        bg_image = crop_resize(bg_image/255, source_image.shape[:2], crop=keep_aspect_background)\n",
        "        imageio.imwrite('/content/bg_crop.png', (bg_image*255).astype(np.uint8))\n",
        "    \n",
        "    with imageio.get_reader(video_path, format='mp4') as reader:\n",
        "        fps = reader.get_meta_data()['fps']\n",
        "    \n",
        "    gpu_ids = \"0\"\n",
        "    num_source = 1\n",
        "    assets_dir = \"/content/drive/MyDrive/Colab/fyp/iPERCore/assets\"\n",
        "    output_dir = \"/content/drive/MyDrive/Colab/fyp/iPERCore/results\"\n",
        "    shutil.rmtree(output_dir, ignore_errors=True)\n",
        "\n",
        "    # symlink from the actual assets directory to this current directory\n",
        "    work_asserts_dir = os.path.join(\"./assets\")\n",
        "    if not os.path.exists(work_asserts_dir):\n",
        "        os.symlink(osp.abspath(assets_dir), osp.abspath(work_asserts_dir),\n",
        "                  target_is_directory=(platform.system() == \"Windows\"))\n",
        "\n",
        "    cfg_path = osp.join(work_asserts_dir, \"configs\", \"deploy.toml\")\n",
        "\n",
        "    model_id = \"mymodel\"\n",
        "    \n",
        "    src_path = \"\\\"path?=/content/crop.png,name?=mymodel\"\n",
        "    if background=='replace' and os.path.exists('/content/bg_crop.png'):\n",
        "      src_path += ',bg_path?=/content/bg_crop.png'\n",
        "    src_path += '\"'\n",
        "\n",
        "    ref_path = \"\\\"path?=%s,\"  \\\n",
        "             \"name?=myoutput,\" \\\n",
        "             \"pose_fc?=%d,\"\\\n",
        "             \"cam_fc?=%d,\"\\\n",
        "             \"fps?=%f\\\"\"%(video_path,pose_fc,cam_fc,fps)\n",
        "    options = ''\n",
        "    if background=='inpaint':\n",
        "        options += ' --use_inpaintor'\n",
        "    \n",
        "    !python -m iPERCore.services.run_imitator --gpu_ids $gpu_ids --num_source $num_source --image_size $image_size --output_dir $output_dir --model_id $model_id --cfg_path $cfg_path --src_path $src_path --ref_path $ref_path $options\n",
        "\n",
        "    return FileResponse('./iPERCore/results/primitives/mymodel/synthesis/imitations/mymodel-myoutput.mp4', media_type=\"video/mp4\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xRxuMq-8UgXa",
        "outputId": "ab137b69-28f1-4826-94e1-f6c03cc6090c"
      },
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url+'/docs')\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: http://8912e456cb09.ngrok.io/docs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [3304]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     115.135.103.230:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "/content/drive/MyDrive/Colab/fyp/ganspace/models/checkpoints/stylegan2/stylegan2_model_512.pt\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "/content/drive/MyDrive/Colab/fyp/ganspace/models/checkpoints/stylegan2/stylegan2_character_512.pt\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "/content/drive/MyDrive/Colab/fyp/ganspace/models/checkpoints/stylegan2/stylegan2_portrait_512.pt\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "/content/drive/MyDrive/Colab/fyp/ganspace/models/checkpoints/stylegan2/stylegan2_model_512.pt\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 500 Internal Server Error\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 369, in run_asgi\n",
            "    result = await app(self.scope, self.receive, self.send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/uvicorn/middleware/proxy_headers.py\", line 59, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fastapi/applications.py\", line 199, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/middleware/errors.py\", line 181, in __call__\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/middleware/errors.py\", line 159, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/middleware/cors.py\", line 86, in __call__\n",
            "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/middleware/cors.py\", line 142, in simple_response\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/exceptions.py\", line 82, in __call__\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/exceptions.py\", line 71, in __call__\n",
            "    await self.app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 580, in __call__\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 241, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 52, in app\n",
            "    response = await func(request)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fastapi/routing.py\", line 220, in app\n",
            "    dependant=dependant, values=values, is_coroutine=is_coroutine\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fastapi/routing.py\", line 152, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "  File \"<ipython-input-62-1715b7b91046>\", line 136, in edit\n",
            "    directions.append(latent_dirs[param_indexes[model_type][k]])\n",
            "KeyError: 'Realism'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n",
            "INFO:     115.135.103.230:0 - \"POST /edit HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [3304]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMBJ8YaOSgd-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}